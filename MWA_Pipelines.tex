%\documentclass[10pt,flushrt,preprint]{aastex}

\documentclass[preprint2]{aastex}

\usepackage{graphicx}
\usepackage[space]{grffile}
\usepackage{latexsym}
\usepackage{amsfonts,amsmath,amssymb}
\usepackage{url}
\usepackage[utf8]{inputenc}
\usepackage{fancyref}
\usepackage{hyperref}
\hypersetup{colorlinks=false,pdfborder={0 0 0},}
\usepackage{textcomp}
\usepackage{longtable}
\usepackage{multirow,booktabs}

\usepackage{natbib}

\newcommand{\truncateit}[1]{\truncate{0.8\textwidth}{#1}}
\newcommand{\scititle}[1]{\title[\truncateit{#1}]{#1}}


%% preprint2 produces a double-column, single-spaced document:

%% \documentclass[preprint2]{aastex}

%% Sometimes a paper's abstract is too long to fit on the
%% title page in preprint2 mode. When that is the case,
%% use the longabstract style option.

%% \documentclass[preprint2,longabstract]{aastex}

%% If you want to create your own macros, you can do so
%% using \newcommand. Your macros should appear before
%% the \begin{document} command.
%%
%% If you are submitting to a journal that translates manuscripts
%% into SGML, you need to follow certain guidelines when preparing
%% your macros. See the AASTeX v5.x Author Guide
%% for information.


%% You can insert a short comment on the title page using the command below.

\slugcomment{tbd journal: MNRAS}

%% If you wish, you may supply running head information, although
%% this information may be modified by the editorial offices.
%% The left head contains a list of authors,
%% usually a maximum of three (otherwise use et al.).  The right
%% head is a modified title of up to roughly 44 characters.
%% Running heads will not print in the manuscript style.

\shorttitle{The MWA Epoch of Reionization Project: Summary of Results}
\shortauthors{D. Jacobs}

%% This is the end of the preamble.  Indicate the beginning of the
%% paper itself with \begin{document}.


%% Use \author, \affil, and the \and command to format
%% author and affiliation information.
%% Note that \email has replaced the old \authoremail command
%% from AASTeX v4.0. You can use \email to mark an email address
%% anywhere in the paper, not just in the front matter.
%% As in the title, use \\ to force line breaks.
\def\eppsilon{{\it $\varepsilon$ppsilon}}
\def\empirical{DILLSPEC}
\def\chipscite{Trott et al 2015}
\def\eppsiloncite{Hazelton et al 2015}
\def\dilloncite{Dillon et al 2015 }




\def\ASU{\altaffilmark{1}}
\def\ASUtxt{\altaffiltext{1}{Arizona State University, School of Earth and Space Exploration, Tempe, AZ 85287, USA}}

\def\myemail{\altaffilmark{*}}
\def\myemailtxt{\altaffiltext{*}{e-mail: daniel.c.jacobs@asu.edu}}

\def\UW{\altaffilmark{2}}
\def\UWtxt{\altaffiltext{2}{University of Washington, Department of Physics, Seattle, WA 98195, USA}}

\def\SKASA{\altaffilmark{3}}
\def\SKASAtxt{\altaffiltext{3}{Square Kilometre Array South Africa (SKA SA), Park Road, Pinelands 7405, South Africa}}

\def\RU{\altaffilmark{4}}
\def\RUtxt{\altaffiltext{4}{Department of Physics and Electronics, Rhodes University, Grahamstown 6140, South Africa}}

\def\CfA{\altaffilmark{5}}
\def\CfAtxt{\altaffiltext{5}{Harvard-Smithsonian Center for Astrophysics, Cambridge, MA 02138, USA}}

\def\ANU{\altaffilmark{6}}
\def\ANUtxt{\altaffiltext{6}{Australian National University, Research School of Astronomy and Astrophysics, Canberra, ACT 2611, Australia}}

\def\CAASTRO{\altaffilmark{7}}
\def\CAASTROtxt{\altaffiltext{7}{ARC Centre of Excellence for All-sky Astrophysics (CAASTRO)}}

\def\Haystack{\altaffilmark{8}}
\def\Haystacktxt{\altaffiltext{8}{MIT Haystack Observatory, Westford, MA 01886, USA}}

\def\MIT{\altaffilmark{9}}
\def\MITtxt{\altaffiltext{9}{MIT Kavli Institute for Astrophysics and Space Research, Cambridge, MA 02139, USA}}

\def\Curtin{\altaffilmark{10}}
\def\Curtintxt{\altaffiltext{10}{International Centre for Radio Astronomy Research, Curtin University, Perth, WA 6845, Australia}}

\def\Victoria{\altaffilmark{11}}
\def\Victoriatxt{\altaffiltext{11}{Victoria University of Wellington, School of Chemical \& Physical Sciences, Wellington 6140, New Zealand}}

\def\UWisc{\altaffilmark{12}}
\def\UWisctxt{\altaffiltext{12}{University of Wisconsin--Milwaukee, Department of Physics, Milwaukee, WI 53201, USA}}

\def\UMichigan{\altaffilmark{13}}
\def\UMichigantxt{\altaffiltext{13}{University of Michigan, Department of Atmospheric, Oceanic and Space Sciences, Ann Arbor, MI 48109, USA}}

\def\UMelbourne{\altaffilmark{14}}
\def\UMelbournetxt{\altaffiltext{14}{The University of Melbourne, School of Physics, Parkville, VIC 3010, Australia}}

\def\USydney{\altaffilmark{15}}
\def\USydneytxt{\altaffiltext{15}{The University of Sydney, Sydney Institute for Astronomy, School of Physics, NSW 2006, Australia}}

\def\CASS{\altaffilmark{16}}
\def\CASStxt{\altaffiltext{16}{CSIRO Astronomy and Space Science (CASS), PO Box 76, Epping, NSW 1710, Australia}}

\def\Tata{\altaffilmark{17}}
\def\Tatatxt{\altaffiltext{17}{National Centre for Radio Astrophysics, Tata Institute for Fundamental Research, Pune 411007, India}}

\def\RRI{\altaffilmark{18}}
\def\RRItxt{\altaffiltext{18}{Raman Research Institute, Bangalore 560080, India}}

\def\NRAO{\altaffilmark{19}}
\def\NRAOtxt{\altaffiltext{19}{National Radio Astronomy Observatory, Charlottesville and Greenbank, USA}}

\def\UWA{\altaffilmark{20}}
\def\UWAtxt{\altaffiltext{20}{International Centre for Radio Astronomy Research, University of Western Australia, Crawley, WA 6009, Australia}}

%% \definenote[thanks][conversion=set 2]

\begin{document}

%% LaTeX will automatically break titles if they run longer than
%% one line. However, you may use \\ to force a line break if
%% you desire.

\title{Murchison Widefield Array Epoch of Reionization Results: Overview and Pipeline comparison}


%% Use \author, \affil, and the \and command to format
%% author and affiliation information.
%% Note that \email has replaced the old \authoremail command
%% from AASTeX v4.0. You can use \email to mark an email address
%% anywhere in the paper, not just in the front matter.
%% As in the title, use \\ to force line breaks.

%% Author list

%TODO fix up author ordering
\include{mwa_eor_collab_latex}
%\author{
%Daniel~C.~Jacobs\ASU\myemail,
%N.~Barry\UW,
%A.~P.~Beardsley\UW,
%G.~Bernardi\SKASA$^,$\RU$^,$\CfA,
%Judd~D.~Bowman\ASU,
%F.~Briggs\ANU$^,$\CAASTRO,
%R.~J.~Cappallo\Haystack, 
%P.~Carroll\UW,
%B.~E.~Corey\Haystack, 
%A.~de~Oliveira-Costa\MIT,
%Joshua~S.~Dillon\MIT,
%D.~Emrich\Curtin,
% B.~M.~Gaensler\USydney$^,$\CAASTRO, 
%A.~Ewall-Wice\MIT,
%L.~Feng\MIT,
%R.~Goeke\MIT,
%L.~J.~Greenhill\CfA,
%B.~J.~Hazelton\UW, 
%J.~N.~Hewitt\MIT,
%N.~Hurley-Walker\Curtin,
%M.~Johnston-Hollitt\Victoria,
%D.~L.~Kaplan\UWisc, 
%J.~C.~Kasper\UMichigan$^,$\CfA, 
%HS Kim\UMelbourne$^,$\CAASTRO,
%E.~Kratzenberg\Haystack, 
%E.~Lenc\USydney$^,$\CAASTRO,
%J.~Line\UMelbourne$^,$\CAASTRO,
%A.~Loeb\CfA,
%C.~J.~Lonsdale\Haystack, 
%M.~J.~Lynch\Curtin, 
%B.~McKinley\UMelbourne$^,$\CAASTRO,
%S.~R.~McWhirter\Haystack,
%D.~A.~Mitchell\CASS$^,$\CAASTRO, 
%M.~F.~Morales\UW, 
%E.~Morgan\MIT, 
%A.~R.~Neben\MIT,
%N.~Thyagarajan\ASU,
%D.~Oberoi\Tata, 
%A.~R.~Offringa\ANU$^,$\CAASTRO, 
%S.~M.~Ord\Curtin$^,$\CAASTRO,
%S. Paul\RRI,
%B.~Pindor\UMelbourne$^,$\CAASTRO,
%J.~C.~Pober\UW,
%T.~Prabu\RRI, 
%P.~Procopio\UMelbourne$^,$\CAASTRO,
%J.~Riding\UMelbourne$^,$\CAASTRO,
%A.~E.~E.~Rogers\Haystack, 
%A.~Roshi\NRAO, 
%N.~Udaya~Shankar\RRI, 
%Shiv~K.~Sethi\RRI,
%K.~S.~Srivani\RRI, 
%R.~Subrahmanyan\RRI$^,$\CAASTRO, 
%I.~S.~Sullivan\UW,
%M.~Tegmark\MIT,
%S.~J.~Tingay\Curtin$^,$\CAASTRO, 
%C.~M.~Trott\Curtin$^,$\CAASTRO,
%M.~Waterson\Curtin$^,$\ANU,
%R.~B.~Wayth\Curtin$^,$\CAASTRO, 
%R.~L.~Webster\UMelbourne$^,$\CAASTRO, 
%A.~R.~Whitney\Haystack, 
%A.~Williams\Curtin, 
%C.~L.~Williams\MIT,
%C.~Wu\UWA,
%J.~S.~B.~Wyithe\UMelbourne$^,$\CAASTRO
%}
%
%%Institutional footnotes (typeset, then rearrange here to be in order)
%\ASUtxt
%\myemailtxt
%\UWtxt
%\SKASAtxt
%\RUtxt
%\CfAtxt
%\ANUtxt
%\CAASTROtxt
%\Haystacktxt
%\MITtxt
%\Curtintxt
%\Victoriatxt
%\UWisctxt
%\UMichigantxt
%\UMelbournetxt
%\USydneytxt
%\CASStxt
%\Tatatxt
%\RRItxt
%\NRAOtxt
%\UWAtxt



%XXX check redshift range 
\begin{abstract}
We present an overview of the Murchison Widefield Array 21\,cm Epoch of Reionization analysis methods in which we compare the output of multiple pipelines as applied to a representative selection of data. The focus of this first round of analysis is on building the methodological foundation for detecting the weak statistical signature of cosmological HI at redshifts between 7.5 and 10 in multi-year observations. This paper provides a top level comparison between multiple, independent, data calibration and reduction pipelines, and from this vantage, assesses their precision.  Each pipeline splits the data analysis into the two steps widely considered to present the most challenges: bright foreground removal and power spectrum estimation. Using a single common data set, we compare images and power spectra produced by matching together different combinations of these two steps with the goal.  Comparing images, we see good agreement between the large scale structures where reionization power is expected to be brightest, with the largest differences having to do with details of how point sources are subtracted in each system. Features common to all power spectra show the continued significance of wide-field effects, while small differences are primarily due to variations in calibration and power spectrum method. One key difference, the choice of weighting in the calculation of the power spectrum limits, is a tradeoff between foreground suppression and signal loss. Here we use multiple weighting schemes, spanning this tradeoff space, to make power spectrum upper limits which we find to be in good agreement with each other and the expected noise.  

\end{abstract}




%% Keywords should appear after the \end{abstract} command. The uncommented
%% example has been keyed in ApJ style. See the instructions to authors
%% for the journal to which you are submitting your paper to determine
%% what keyword punctuation is appropriate.

%\keywords{globular clusters: general --- globular clusters: individual(NGC 6397, NGC 6624, NGC 7078, Terzan 8}

\bibliographystyle{apj_w_etal}


\section{Introduction} 
  Study of primordial Hydrogen  in the early universe via 21\,cm radiation has been forecast to provide a wealth of astrophysical and cosmological information.   Hydrogen is the principal product of big bang nucleosynthesis and is neutral over cosmic time from recombination until reionized by the first batch of UV emitters (stars and accretion disks). While neutral it is visible in the 21\,cm radio line, which is both optically thin and spectrally narrow, making possible full tomographic reconstruction of a very large fraction of the cosmological volume.  Reviews of 21 cm cosmology, astrophysics and observing can be found in \cite{Morales:2010p8093,Furlanetto:2006p2267,Pritchard:2012p9555,zaroubi2013epoch}.
  
Direct detection of HI during the Epoch of Reionization (cosmological redshifts $5<z<13$) is currently the goal of several new radio arrays. The LOw Frequency ARray \citep[LOFAR;][]{Yatawatta:2013p9699}, the Donald C. Backer Precision Array for Probing the Epoch of Reionization \citep[PAPER][]{Parsons:2014p10499} and the Murchison Widefield Array (MWA; \cite{Tingay:2013p9022,Bowman:2013p9950}) are all currently conducting long observing campaigns.



The analysis of the resulting data presents several challenges. The signal is faint; initial detection is being sought in the power spectrum with thousands of hours (multiple seasons) of integration required. This faint spectral line signal sits atop a continuum foreground four orders of magnitude brighter. At the same time, the instruments are fully correlated phased arrays with wide fields of view that strain the conventional mathematical approximations of radio astronomy practice. The methods used to arrive at a well calibrated, foreground-free, estimation of the power spectrum are all under development in the sense of the algorithms as well as the implementation.  


The path from observation to power spectrum can be roughly divided into two parts: removal of foregrounds and estimation of power spectrum. 
Methods for estimating the power spectrum, particularly those which minimize the effects of foregrounds, have been studied and implemented by \citet{Morales:2006p1870,Morales:2012p8790,Dillon:2013p10497,Dillon:2014p9788,Liu:2011p8763,Liu:2014p10462,Liu:2014p10463,Trott:2012p10466}. Essential elements include using knowledge about the instrument and foregrounds to minimize covariance, applying an optimal quadratic estimator to make a minimal error estimate, and studies of effects related to including the spectral dimension in the Fourier transform.  One significant problem studied has been minimizing the impact of any residual foregrounds by down-weighting or minimizing correlation with contaminated band powers. In this paper we compare power spectra calculated using a range of methods. 

Most power spectrum analyses require removal of bright foregrounds to some level.  Recently, two sorts of foreground removal have been suggested: methods which exploit detailed knowledge of foregrounds and those which are relatively agnostic. Among the latter, several authors have described methods for fitting and removing smooth spectrum foregrounds from image cubes  \cite{Morales:2006p1903,Bowman:2009p7816,Liu:2009p4762,Liu:2011p8763,Chapman:2013p10379,Dillon:2013p10497,Yatawatta:2013p9699}. These methods have been demonstrated to robustly remove foregrounds near the field center but are less effective for sources far from the central lobe of the primary beam.  A second class of agnostic methods is the delay/fringe-rate filtering approach \citep{Parsons:2012p8896,Liu:2014p10462,Liu:2014p10463}, which has been applied to data from PAPER \citep{Parsons:2014p10499}.  Applying time and frequency domain filters to the time ordered data, this technique uses a small amount of knowledge about the instrument to filter modes likely to be dominated by foregrounds.  This method removes smooth spectrum foregrounds across the entire sky and is comparatively robust in the face of uncertainty about the instrument at the cost of losing some sensitivity.  Meanwhile, full forward modeling and subtraction of sky model such as that implemented for LOFAR (see e.g. \cite{Jelic:2008p2130,Yatawatta:2013p9699}), requires a much higher fidelity model of the instrument and the sky \citep{Datta:2010p8781,Vedantham:2012p10297}.


The MWA foreground removal approach leverages the array's optimization for imaging to directly subtract known foregrounds in addition to the full range of treatments of residual foregrounds, including foreground avoidance and foreground suppression.  If successful, direct subtraction opens the most sensitive power spectrum modes substantially improving the ability of early measurements to distinguish between reionization models \citep{Beardsley:2013p9952,Pober:2014p10390}. Recent work towards the goal of foreground subtraction includes better algorithmic handling of wide field imaging effects \citep{Tasse:2012p9459,Bhatnagar..2013ApJ,Sullivan:2012p9457,Ord:2010p8442}, and continually improving catalogs of sky emission \citep{deOliveiraCosta:2008p2242,Jacobs:2011p8438,Hurley-walker:2014p45,2014AAS...22342101M}. Ongoing operation of the next generation low frequency arrays --LOFAR, PAPER and MWA are all in their  third or fourth year of operation-- continues to push the refinement of instrumental models (e.g. the work of \cite{Neben:2015pxxx} in mapping the primary beam with satellites) and improve the accuracy of model subtraction.  At the same time, more complete surveys of foregrounds are currently under way. These include the MWA GLEAM\footnote{GLEAM: GaLactic and Extragalactic All-sky MWA} survey \citep{Wayth:2015arXiv150506041W}  and the LOFAR MSSS\footnote{MSSS: Multi-frequency Snapshot Sky Survey}.   

In turn, efforts with these currently operational experiments are having a major influence on how future, larger, EoR experiments will be designed and conducted.  Primary among these future experiments will be programs using the low frequency Square Kilometer Array (\cite{2014aska.confE...1K}) and the Hydrogen Epoch of Reionization Array \citep[HERA][]{Pober:2014p10390}.  Specifically, the MWA is one of three official precursor telescopes for the SKA and the only one of the three fully operational for science.  The low frequency SKA will be located at the MWA site in Western Australia, giving the MWA special significance.

Given the challenges of using newly developed methods to reduce data from a novel instrument to make a low sensitivity detection, it is reasonable to consider the question of how one knows one is getting the ``right'' answer.  One option is to generate, as accurately as possible, a detailed simulation of the interferometer output and then input that to the pipeline under test.  Such forward modeling is an essential tool for checking correct operation of portions of the pipeline, however the model will always be an imperfect reflection of reality, leaving open multiple interpretations of any differences between model and ata.  Forward modeling the instrument response is also difficult to divorce from the analysis pipeline being tested; often the same software doing the analysis is used to perform the simulations. A second option, and the focus of this paper, is comparison between multiple independent pipelines.% Development of a completely independent instrumental simulation is the subject of ongoing work \citep[see e.g..][]{2015arXiv150207596T}.  The second option is more pragmatic; compare the results of multiple independent pipelines operating on real data.
In this paper we apply several MWA pipelines --described in detail in companion papers-- comparing their power spectrum outputs to assess the accuracy of their limits on 21\,cm emission during reionization.  Within the MWA collaboration efforts have centered around multiple independent paths from raw data to a power spectrum.  As described in Figure \ref{fig:pipes}, these pipelines are generally divided into a component which performs calibration, foreground subtraction and imaging, and one which computes the power spectrum.  During development, each power spectrum code was paired with a ``primary'' foreground subtraction method.  Though the main results come from these primary paths (as depicted by the thin lines in Figure \ref{fig:pipes}). These results are then checked by cross-connecting the pipelines at intermediate points, with the goal of separating effects common to specific codes or algorithms.

The analysis presented here is on three hours of data, one of 400 nights which have been collected as part of the MWA 21\,cm observing program; 150 nights are thought to be necessary for a detection of typical models \citep{Beardsley:2013p9952}. The 400 nights span multiple tunings, pointings, and observing conditions. Here we have limited the analysis to one representative night with the goal of validating our instrument model, sky model, and power spectrum methods on a well understood data set. 

% a representative sample of the observing program which is repeated nightly. The amount of data required to detect a fiducial 21\,cm emission model is thought to be around 450 hours \citep{Beardsley:2013p9952} or about 150 nights.  The MWA 21\,cm program has recorded over 1000 hours of data spanning multiple fields, tunings, and observing conditions. A night is the smallest complete amount of data, larger amounts of data are just repeated measurements, and is enough to build confidence in the accuracy of our pipelines and establish the framework of independent pipeline comparison.



%Development of a pipeline that fully models the telescope for each of many hundreds of snapshots is a laborious process and subject to error. Another goal of the pipeline comparison process is to produce reliable averaged products suitable for a more comprehensive analysis. One example of such a process is \empirical{}. Whereas both \eppsilon{} and CHIPS take as input many short snapshots, \empirical{} takes, as input, single cubes of integrated data and uses an empirical estimate of the instrumental covariance to mitigate any remaining residual in the Fourier modes due to instrument mis-modeling in the previous steps.  

%TODO I really don't like this paragraph's location in the flow.  but I didn't like putting it in the Observation section very much either
% Though the MWA EoR program has collected more than 1000 hours of data but here we will limit ourselves to a single night (3 hours) an amount which is sufficient to gain insight into the performance of our calibration algorithms and foreground subtraction models without adding the complexity of a large dataset. % Upcoming analyses will focus on going deeper, using analysis techniques built upon the foundation methods described here and in companion papers.


In section \ref{sec:observing} we summarize the observing strategy used to collect our data, section \ref{sec:pipelines} explains our multiple pipelines and comparison strategy. In section \ref{sec:results} we show comparisons of images, 2D diagnostic power spectra and 1D power spectrum limits, and conclude in section \ref{sec:conclusion} with an overview of lessons learned from the comparison process and directions of future work .



\section{Observing}
\label{sec:observing}
%The MWA
\subsection{The MWA}
The MWA is an interferometric array of phased array tiles operating in the 80-300\,MHz radio band. Each tile consists of a 4x4 grid of bow-tie shaped dipoles that are used to form a beam on the sky with a full width of 26\arcdeg$\lambda$ at the half power point. Signals from individual antennas are summed by an analog, delay-line, beamformer which can steer the beam in steps of 6.8\arcdeg$cos(l)$.  The signal is digitized over the entire bandwidth but only 30\,MHz are available at any one time.  This 30\,MHz of bandwidth is broken into 1.28\,MHz ``coarse'' bands by a polyphase filter-bank in the field and sent to the correlator \citep{Ord:2015PASA...32....6O} where it is further channelized to 40kHz, cross-multiplied and then averaged at 0.5 second intervals.  More details on the design and operation of the MWA can be found in \cite{Lonsdale:2009p7913} and \cite{Tingay:2013p9022}.

%TODO maybe move this elsewhere.
%The spectral shape of the coarse polyphase filter is known somewhat imperfectly and is thought to include a small amount of aliasing from adjacent coarse channels, though the exact amount is currently under investigation. This spectral response is corrected to first order during the first post-correlator step, and to second order by the calibration step.
%The EoR program
\subsection{The 21\,cm Observing Program}
The MWA EoR observing scheme spans two 30\,MHz tunings, 140-170\,MHz (9.2$<z<$7.5) and 167-196\,MHz (7.5$<z<$6.25) and two minimal foreground regions (RA 0h and 4h, Dec -27\arcdeg); both transit the zenith at the MWA's  latitude and are near the galactic pole. Here we focus on the low redshift tuning, and the RA=0h pointing, where the band is chosen for its lower sky temperature and pointing is chosen for its ease of calibration --having fewer bright, resolved sources; see Table \ref{tab:observing} for a listing of observing parameters.
%The data included here
\subsection{Data Included Here}
During observing, the beam-former was set such that the target region repeatedly drifted through the field of view.  With an available beamformer step size of 6.8\arcdeg; each drift was about 30 minutes long.  This was done for a total of 6 pointings in a night, or about 3 hours. The data included here include the two pointings leading up to the target crossing zenith, the zenith pointing, and then three more pointings after the transit crossing.  Data were recorded in 112 second units for a total of 96 snapshots. These snapshots are the basic unit of time on which many operations become independent -eg RFI flagging, FHD calibration and imaging.\footnote{Note that this is not true in the RTS which uses a time interval scaled by the baseline length.}   Each snapshot is flagged for interference using the AOFlagger \citep{offringa:2010rfim.workE..36O}\footnote{ \url{sourceforge.net/projects/aoflagger} } algorithm and then averaged to 2 seconds and 80kHz.  As described in \cite{2015PASA...32....8O}, the interference environment at the Murchison Radio Observatory is benign and generally requires flagging of about 1\% of the data.   Though the full set of linear polarization parameters are correlated, and Stokes I images and power spectra are the final product of interest, at this stage of the analysis the instrumental polarizations have been found to be more instructive; with one exception, only the linear X (east-west) polarization is examined here.   The same set of snapshots is used in every pipeline run.


\begin{deluxetable}{lcr}
\tablecolumns{2}
\tablecaption{MWA EoR Observing Parameters }
\tablehead{
\colhead{parameter}  & 
\colhead{value} 
}
\startdata
field of view & 26\arcdeg$\lambda$ FWHM \tabularnewline
tuning & 166-196\,MHz  redshift range $7.56<z<6.25$ \tabularnewline
target area & (RA,Dec) 0h00m, -27\arcdeg00m \tabularnewline
primary beam pointing grid & 6.8\arcdeg \tabularnewline
snapshot length & 112 seconds\tabularnewline
time and frequency resolution & 0.5\,s, 40 kHz  \tabularnewline
post-flagging resolution & 2s, 80\,kHz \tabularnewline
time & 3 hours on August 23, 2013, six 30 minute pointings or 96 snapshots\tablenotemark{a} 
\tabularnewline
\enddata
\tablenotetext{a}{The same data set is used in every pipeline run}
\label{tab:observing}
\end{deluxetable}





\section{Power Spectrum Pipelines}
\label{sec:pipelines}
In this section we review the basic analysis components, introduce the basic pipeline components, define some terms common to all, and then in sections \ref{sec:RTS}-\ref{sec:CHIPS} give finer grain descriptions of the specific implementations.

%about the power spectrum
The 21\,cm brightness at high redshift is weak and detectable by first generation instruments only in	 statistical measures such as the power spectrum. The spectral line signal is a three dimensional probe, two spatial dimensions and a third from the mapping of the spectral axis to line-of-sight distance via the Hubble relation. 3D power spectra are computed at multiple redshift slices through the observed band and then, taking advantage of statistical rotational symmetry, averaged in shells of constant wavenumber $k$.  The power spectrum is well matched to an interferometer, which natively measures spatial correlation; the baseline vector maps to the perpendicular wavemode $k_\perp$.  An additional Fourier transform in the spectral dimension provides $k_\parallel$.  

%about foregrounds
The principle challenge to detecting 21\,cm at very high redshifts is foreground emission. At frequencies below 200\,MHz the principle sources are synchrotron emissions from the local and extragalactic sources. Synchrotron is generally characterized by a smooth spectrum which rises as a power law towards lower frequencies. The local Galactic neighborhood has a significant amount of spatially smooth power appearing at short $k_\perp$ modes, extragalactic point sources appear equally on all scales and dominate over the Galaxy on long $k_\perp$ modes.

%about foreground subtraction
An analysis pipeline has two main components: one which removes foregrounds --leaving as small a residual as possible-- and a second which computes an estimate of the power spectrum.   Foreground subtraction is generally the domain of calibration and imaging software where the focus is on building an accurate forward model of the telescope and foregrounds.  Challenges include: ionospheric distortion, a very wide field of view, primary beam uncertainty, polarization leakage, and catalog inaccuracy. Though a number of calibration and imaging software packages --such as CASA and Miriad-- are available, these challenges have necessitated the creation of custom software.  As an added benefit, having developmental control of the imager enables the export of the instrument model in the form of weights and variance cubes which are necessary for the calculation of power spectrum error bars as described below. 

As we mentioned in the introduction, a horizon-to-horizon model of the sky must be subtracted at high precision from each two minute snapshot across thousands of hours of data. At this scale, deconvolution and self-calibration of each snapshot image is not computationally tractable.  In both FHD and RTS the sky model is left static and instead the focus is on refining the instrument model used in forward modeling and averaging of calibration solutions.  This instrument model also provides information on the instrumental covariance.


%about power spectrum estimation and why we need an instrument model
Detailed knowledge of instrumental covariance is essential to overcoming the two main challenges in estimating the power spectrum: 1) minimizing the effects of residual foregrounds and 2) faithfully recovering the underlying 21\,cm power.   As discussed in the introduction, simulations and early observations have shown that foregrounds tend to ``contaminate'' only specific $k$ modes, using a model of instrumental covariance the power can be isolated to fewer modes.  Accurate recovery of the 21\,cm background will, to first order, depend on the ability to correctly calculate error bars.  Initial power spectra are expected be of low signal to noise, an accurate estimate of error is essential to estimating the significance of any putative detection \citep{Pober:2014p10390,Beardsley:2013p9952}. 

%about the pipelines.
Pipeline development has centered around the construction of two main end-to-end analysis tracks shown in Figure \ref{fig:pipes} and described in more detail in \chipscite{} and \eppsiloncite{}. A third pipeline described in \dilloncite{} substitutes an alternate power spectrum calculation method in place of \eppsilon{}. The primary difference between these pipelines is the division of responsibilities between foreground subtraction and power spectrum calculation. Some power spectrum methods take as input spectral image cubes output by the calibration and foreground subtraction system.  The imager also provides a model of the telescope window function (variance) in the form of a cube of weights (weights squared) formed by gridding down `1's in the same way as the data. These encode the full covariance of the telescope's window function.  Each set of cubes is generated with both even and odd sample cadences; the cross multiplication provides a power spectrum free of noise bias and the difference an estimate of noise.

Methods which take time-ordered data as input generate their own instrument model internally.  The pipeline submodules names and citations are listed in Table \ref{tab:pipeline_cites} and described individually in sections \ref{sec:RTS} - \ref{sec:empirical_cov}.  

\begin{deluxetable}{llr}
\tabletypesize{\footnotesize}
\tablecolumns{2}
\tablecaption{MWA EoR Pipeline components }
\tablehead{
\colhead{Short Name} &
\colhead{Name}  & 
\colhead{Citations} 
}
\startdata
Cotter & AOFlagger + Averaging & \cite{offringa:2010rfim.workE..36O} \tabularnewline
RTS & Real Time System&\cite{Mitchell:2008p707,Ord:2010p8442} \tabularnewline
FHD & Fast Holographic Deconvolution &\cite{Sullivan:2012p9457}\tablenotemark{1}  \tabularnewline
\eppsilon{} & Error Propagated Power Spectrum with InterLeaved Observed Noise & \eppsiloncite{}\tablenotemark{2} \tabularnewline
CHIPS & Cosmological HI Power Spectrum& \chipscite{}  \tabularnewline
\empirical{} & Empirical Covariance Estimator & \dilloncite{}


\enddata
\tablenotetext{1}{\url{github.com/miguelfmorales/FHD}}
\tablenotetext{2}{\url{github.com/miguelfmorales/eppsilon}}
\label{tab:pipeline_cites}
\end{deluxetable}



% End-to-end pipes FHD-\eppsilon
%One pipeline uses Fast Holographic Deconvolution (FHD\footnote{\url{github.com/miguelfmorales/FHD}}) for calibration and foreground subtraction, followed by either \eppsilon\footnote{\eppsilon:Error Propagated Power Spectrum with InterLeaved Observed Noise; \url{https://github.com/miguelfmorales/eppsilon}} or \empirical{} \dilloncite{} to estimate the power spectrum. 
%
%The independent  pipeline uses an offline version of the MWA Real Time System (RTS) followed by CHIPS\footnote{Cosmological HI Power Spectrum} to estimate the power spectrum.  FHD is described in detail by \cite{Sullivan:2012p9457} and the RTS by \cite{Ord:2010p8442}. \eppsilon{}, CHIPS and \empirical{}, as applied to the data published here, are described in \eppsiloncite{}, \chipscite{}, and \dilloncite{}, respectively.

%TODO  move more common elements into this section 
% TODO mention major and minor connections between pipeline elements here at the top


   
   
%   Models (cites) and arguments from isotropy and homogeneity suggest that over redshift ranges less than 0.5, 21\,cm emission is statistically rotationally symmetric; the 1D power spectrum, averaged in shells of constant wavenumber ($k$), preserves cosmological signal. 
  
    
%  The MWA collaboration has developed two independent pipelines which take in raw, time-ordered data and output a power spectrum.  Key steps include calibration to a sky model, subtraction of bright foregrounds, generation of image cubes,  transformation into 3D Fourier space, and estimation of the 1D spherically averaged power spectrum.
%  
%  calibration and imaging modules which subtract the foregrounds and two power spectrum estimators. All are developed independently, sharing very little code, yet are interconnectable via common data formats to give four possible pipeline paths.These two paths and their interactions are sketched out in Figure \ref{fig:pipes}.


%The imaging and foreground subtraction portion of the pipeline can be handled by either of two custom packages.  The MWA Real Time System (RTS; \cite{Ord:2010p8442}) was initially designed to make images in real time from the MWA 512.  On the de-scoped 128 element array, it has been implemented as an offline system, where it has been adjusted to compensate for the lower filling factor.  Fast Holographic Deconvolution (FHD; \cite{Sullivan:2012p9457}) is a custom interferometric imaging package developed for interferometric instruments with a focus on accounting for very wide field of view antenna responses found on phased arrays of dipoles.  Both systems were developed in parallel with the construction and commissioning of the MWA to provide a detailed introspection on unique aspects of this experimental telescope. Each can calibrate a data set against a model, subtract a model, deconvolve images and use precision models of the instrument informed by the commissioning process including effects such as tile to tile primary beam variation and 0.1dB cable reflections.  Foreground inputs include catalogs, images of extended emission and wavelet models of bright, mostly compact, sources.  In addition, each has its own unique feature set developed as part of the experimental process.

\begin{figure*}[htbp]
\begin{center}
\includegraphics[width=\textwidth]{figures/MWA_Pipes.png}
\caption{Parallel pipelines with cross-connections after foreground subtraction and imaging are compared against each other. Pipelines used to reach the cited power spectrum results are indicated with thin lines; citations for each block are listed in Table \ref{tab:pipeline_cites}. Cotter uses AOFlagger to flag RFI and averages by a factor of 8. The averaged data are passed to either FHD or RTS for calibration, foreground subtraction and imaging. Both of these packages generate integrated residual spectral image cubes as well as matching cubes of weights and variances.  \eppsilon{} and \empirical{} use these cubes to estimate the power spectrum. Meanwhile, CHIPS taps into the RTS and FHD data stream to get calibrated and foreground-subtracted time-ordered  visibilities which it then grids with its own instrument model to estimate the power spectrum. 
%imager produces an image, instrument model (weights and variances)
}
\label{fig:pipes}
\end{center}
\end{figure*}

\subsection{Calibration and Imager \#1: RTS}
\label{sec:RTS}

{\bf NOTE: This section needs to be checked and corrected by Bart or Pietro}

%TODO
The MWA Real Time System (RTS; \cite{Ord:2010p8442}) was initially designed to make wide-field images in real time from the MWA 512-tile system \citep{Mitchell:2008p707}.  On the de-scoped 128 element array, it has been implemented as an offline system, where it has been adjusted to compensate for the lower filling factor \citep{Ord:2010p8442}.  The RTS incorporates algorithms intended to address a number of known challenges inherent to processing MWA data, including; wide-field imaging effects, direction-dependent (DD) antenna gains and polarization response, and ionospheric refraction of low-frequency radio waves. Each MWA observation (112s) is processed through a separate instance of the RTS. The RTS is also parallelized over frequency so that each coarse channel (1.28\,MHz broken into 40 kHz channels) is processed largely independently of the other coarse channels, with only information about the measured ionospheric offsets communicated between processing nodes.  Calibration and model subtraction were based on the Molonglo Reference Catalog \citep{Large:1981p7798}. 

The RTS calibration strategy is based upon the `peeling' technique proposed by \cite{Noordam:2004p2379}. The brightest apparent calibrators in the field of view are sequentially and iteratively processed through a Calibrator Measurement Loop (CML). During each pass through the CML; i) the expected (model) visibilities of known catalogue sources are subtracted from the observed visibilities. For the data processed in this work, $\sim$100 sources are subtracted for each observation. ii) The model visibilites for the targeted source are added back in and phased to the catalog source location. Any ionospheric offset of the source can now be measured by fitting a phase ramp to the phased visibilities. iii) The strongest sources are now used to update the direction-dependent antenna gain terms, while weaker sources are only corrected for ionospheric offsets. For this work, 100 sources are used as full DD calibrators and 300 sources are set as ionospheric calibrators. The CML is repeated until the gain and ionospheric fits converge to stable values. A single bandpass for each tile is found by fitting a 2nd order polynomial to each coarse channel. The $\sim$300 strongest sources are then subtracted from the calibrated visibilities.   Calibration and model subtraction parameters are summarized in Table \ref{tab:cal_sub_parms}.  Model subtracted visibilities are passed to the RTS imager and to the CHIPS power spectrum estimator. %how much flux is subtracted in total?
%TODO WTF is this Clark Allen Arcus paper!
The RTS imager uses a snapshot imaging approach to correct for wide-field and direction-dependant polarization effects. Following calibration, the residual visibilities are first gridded to form instrumental polarization images which are co-planar with the array. These images are then regridded into the HEALPIX \citep{Gorski:2005p7667} frame with wide-field corrections.  Weighted instrument polarisation images are stored, along with weight images containing the Mueller matrix terms, so that further integration can be done outside of the RTS. It is also possible to use the fitted ionospheric calibrator offsets to apply a correction for ionospheric effects across the field during the regridding step or subtraction of catalog sources, but in this work this correction has not been applied. These snapshot data and weight cubes are then integrated in time to produce a single healpix cube. This cube, averaged over the spectrum, is shown, with and without foregrounds, in Figure \ref{fig:image_compare}.


\begin{deluxetable}{lll}
\tablecolumns{3}
\tabletypesize{\footnotesize}
\tablewidth{0pt} 
\tablecaption{MWA EoR Calibration and Model subtraction Parameters }
\tablehead{
\colhead{correction}  & 
\colhead{RTS} &
\colhead{FHD} 
}
\startdata
global passband & NA & 768 channels  \\
per antenna passband & 48 per tile\tablenotemark{a} & 3 per tile\tablenotemark{b}\\
per antenna gain & 2\tablenotemark{c} & 2\tablenotemark{c}  \\
peeling parameters & 4\tablenotemark{d} & None \\
peeled sources & 5 & None\\
subtraction catalog & MRC\tablenotemark{e} & Carroll\tablenotemark{f} \\
number subtracted & 300 & 1000 \\
\bf{Total free parameters} & \bf{6,420} & \bf{1,408} \\
\enddata
\tablenotetext{a}{2nd order poly per coarse channel}
\tablenotetext{b}{poly fit over full band, 2nd order for amp, 1st for phase}
\tablenotetext{c}{amplitude and phase}
\tablenotetext{d}{Direction Dependent (DD) gain fits}
\tablenotetext{e}{Molonglo Reference Catalog \citep{Large:1991p7760}}
\tablenotetext{f}{Sources deconvolved from snapshots with FHD, (Carroll et al in prep)}
\label{tab:cal_sub_parms}
\end{deluxetable}



\subsection{Calibration and Imager \#2: FHD}
\label{sec:FHD}
Fast Holographic Deconvolution (FHD, \cite{Sullivan:2012p9457}) is a calibration and imaging algorithm designed for very wide field of view interferometers with direction- and antenna-dependent beam patterns using the tile beam pattern to grid visibilities to the $uv$ plane, and its Hermitian conjugate for de-gridding simulations to form model visibilities. 

The FHD calibration pipeline generates a model data set, computes a calibration solution which minimizes the difference with the data, smooth the calibration solution to minimize the number of free parameters, and then outputs the residual. The calibration model is formed from sources found by deconvolving, in broadband images, hundreds of snapshots and retaining those which are common to all snapshots and pass other consistency checks (Carroll et. al. in prep). In each snapshot sources are included in the model if they are at or above 1\% of the peak primary beam, this amounts to about 1000 sources and a flux limit of about 1Jy (it varies slightly snapshot to snapshot). %TODO: check this flux cut.

 Per-antenna and per-channel complex gain solutions are then computed using the Alternating Direction Implicit technique described in \citet{sal14}.  This generates a gain and phase for every channel on every tile, for each 112s snapshot.  These solutions are then averaged over all tiles to form a single passband, which corrects for the majority of the spectral dependent effects such as the response of the coarse channel passband and cable attenuation.  This single passband solution is divided out of each per tile solution and each residual fit for a 2nd order amplitude polynomial and a first order phase polynomial. This process happens iteratively, with convergence measured by comparing the relative difference between residual visibilities. 10 iterations to converge to a stable residual was the norm.  The residual time-ordered visibilites are then passed to CHIPS and to FHD imaging for formation of spectral cubes.  The FHD imager  produces snapshot cubes using the MWA beam model described by \cite{Sutinjo:2015RaSc...50...52S} and averaged in time. This image, further averaged over the spectrum, is shown, with and without foregrounds, in Figure \ref{fig:image_compare}.

\subsection{Comparing Calibration and Imaging Steps}
\label{sec:comparing_imaging}
Through the parallel-but-convergant development of these imagers have emerged two very similar systems, however some differences remain in the analysis captured here. The two primary differences are in the treatment of calibration and in the subtracted catalogs.  

In both pipelines the calibration is a two step process. First, calibration solutions for each channel, and antenna are computed by solving for the least-squares difference with a model data set. Next, those solutions are fit to a model of the array; for example fitting a polynomial to the bandpass. FHD and RTS take different approaches to this step, a fact reflected in the the number of free parameters in this fit. A smaller number of parameters minimizes the possibility of cosmological signal loss; more free parameters can absorb physics missing from the instrument model.  As tabulated in Table \ref{tab:cal_sub_parms} the RTS fits for 6,420 free parameters while FHD fits for 1,408.  In practice this is a lower limit as it does not count any antennas which might be flagged during the calibration process. The primary difference is in the treatment of the passband.  The spectral shape of the coarse polyphase filter is known somewhat imperfectly. This spectral response is corrected to first order during the first post-correlator step, and to second order by the calibration step. The RTS fits for a low order polynomial on every 1.28\,MHz chunk on every antenna, while FHD averages each channel over all antennas to get a common passband for all and then fits a low order polynomial to get any tile to tile variation. This significantly reduces the number of free parameters and the likelihood of signal loss.

The selection of foreground subtraction model is a tradeoff between accuracy and stability.
As noted in Table \ref{tab:cal_sub_parms}, the RTS foreground model contains 300 Molonglo Reference Catalog sources. This selection from the Molonglo catalog includes bright sources found at 408\,MHz and contains spectral indices where higher frequency data are available. The reliability at lower frequencies is less certain, however the choice of using MRC has the strength of being completely de-coupled from the data under study thereby reducing one more source of error. Conversely, the FHD subtraction model contains 1000 sources found in an FHD deconvolution of this same data set which will be described in more detail by Carroll et. al. (in prep).  Since the catalog is made at the desired frequencies, no extrapolation along spectral index is required. This improves both detection reliability and flux accuracy.
%TODO I am not completely happy with the above paragraph.


\begin{figure*}[htb]
\begin{center}
\includegraphics[width=1\textwidth]{figures/FHD_RTS_dirty_compare_31March2015_polswitch.png}
%\includegraphics[width=1\textwidth]{figures/FHD_2014c_RTS_March_2015_polswitch.png}
%\includegraphics[width=1\textwidth]{figures/FHD_2014c_RTSnominal_polswitch.png}
\includegraphics[width=1\textwidth]{figures/FHD_2014c_RTS_Aug_res.png}
\caption{A comparison between the image outputs of the FHD (left), RTS (center) and their difference (right) averaged in the spectral dimension and projected from native healpix to flat sky.  In the top row, no foreground model has been subtracted, on the bottom FHD has subtracted $\sim$1000 sources and RTS has subtracted 300.  Both have been left in the natural weighting used by image-based power spectrum schemes. The difference between foreground subtracted images reveals a good agreement on large scale structure and small differences in the fluxes of a few sources.
%TODO this caption could be improved
\label{fig:image_compare}}
\end{center}
\end{figure*}

%Numbers
%RMS
%comparison : FHD, RTS,diff (all in Jy)
%dirty             : 1.97,1.46,0.544  (30\%)
%best             : 0.924,0.815,0.397 (50\%)
%
%
%Means
%comparison : FHD,RTS,diff (all in mJy)
%dirty             : 59,42,17  (17\%)
%best             : 32,29,2.8  (9\%)



%\begin{deluxetable}{lccr}
%\tablecolumns{4}
%\tablewidth{0pt}
%\tablecaption{Foreground subtraction image differences }
%\tablehead{
%\colhead{\parbox{10em}{Number of sources subtracted FHD/RTS}}  & 
%\colhead{FHD RMS\tablenotemark{*}} &
%\colhead{RTS RMS\tablenotemark{*}}&
%\colhead{diff RMS\tablenotemark{*}}
%}
%\startdata
%None/None & 1.97 & 1.49 & 1.08 \tabularnewline
%300/300 & 1.19 & 0.59 & 0.991 \tabularnewline
%1000/300 & 0.923 &  0.59 & 0.817
%%None/None & 1.97 & 1.49 & 1.08 \tabularnewline
%%300/300 & 1.19 & 0.66 & 0.991 \tabularnewline
%%1000/300 & 0.923 &  0.483 & 0.806
%\enddata
%\label{tab:image_comparison}
%\tablenotetext{*}{The standard deviation of the image in Jy}
%\end{deluxetable}

\subsection{Power Spectrum \#1: \eppsilon}
\label{sec:EPPSILON}
\eppsilon{} calculates a power spectrum estimate from image cubes and
directly propagates error bars through the full analysis, see \eppsiloncite{} for a full description. The design criteria for this method is to make a relatively quick and uncomplicated estimate of the power spectrum to provide a quick turnaround diagnostic. The input to \eppsilon{} is gridded image cubes for  each 112s snapshot, such as are produced by FHD or RTS imaging, in which the data has been split into interleaved time samples (referred to as even and odd cubes) along with matched cubes containing the modeled instrumental weighting and variance. These snapshot healpix cubes are integrated in time keeping pixels with a beam weight of 1\% or more, a cut which effectively limits the field of view to $\sim$20\arcdeg. The accumulated data, weight and variance cubes are Fourier transformed in two dimensions to take them to $uvf$ space where the spatial covariance matrix is assumed to be diagonal. This is a better assumption if the $uv$ pixel size is well matched to the primary beam size so we restrict the spacing of modes in the spatial DFT to be equal to the inverse of the primary beam field of view. The data (variance) cubes are then divided by the weight cubes (weight cubes squared) to arrive at the best estimates of the sky and variances. Next the sum and difference of the even and odd cubes are computed with variances given by adding the reciprocal of the even and odd variances in quadrature. The difference cube then contains only noise (as long as the time interleaving is fine enough) and the sum cube contains both sky signal and noise.

The next step is to Fourier transform in the frequency direction. Here we choose to use the full 30\,MHz spectral window, weighted by a Blackman-Harris window function, which heavily down-weights the outer half of the band to effectively sample 15\,MHz; a cosmological redshift range of 0.86. This weighting scheme minimizes the covariance of bright foreground modes between power spectrum modes as described in \cite{Thyagarajan:2013p10039,Parsons:2012p8896,Vedantham:2012p9026}, among others.  The spectral Fourier transform uses the Lomb \& Scargle periodogram to minimize the effects of regular gaps in the spectrum which occur every 1.28\,MHz.    The sky signal power is  estimated by the square of the sum cube minus the square of the difference cube, which  is mathematically identical to the even/odd cross power if the even and odd variances are identical, while the square of the difference cube provides a realization of the noise power spectrum. Diagnostic power spectra in which the wedge is visible are generated by averaging cylindrically to a two dimensional $k_{\|}-k_{\bot}$ power spectrum.  These are shown in the left column of Figure \ref{fig:pspec_compare}.  One dimensional power spectra (shown in Figure \ref{fig:1D_pspecs}), are calculated by averaging along shells of constant $k$, masking points within the wedge and weighting by variance\footnote{Here defined, conservatively, as the light travel time across the baseline plus the delay associated with the pointing furthest from zenith}.

%TODO 1D power spectra?





\subsection{Power Spectrum \#2: CHIPS}
\label{sec:CHIPS}
The CHIPS power spectrum estimation method computes the maximum likelihood estimate of the 21~cm power spectrum using an optimal estimator formalism and is more completely described in \chipscite{}.  The design criteria for this method were to fully account for instrumental and foreground induced covariance in the estimation of the power spectrum.  The approach is similar to that used by \cite{Liu:2011p8763}, but with the key difference of being performed entirely in $uv$-space, where the data covariance matrix is simpler (block diagonal), and feasible to invert. This approach also allows straightforward estimation of the variances and covariances between sky modes by direct propagation of errors. CHIPS takes as input calibrated and foreground subtracted time-ordered visibilities. Tapping into the pipeline post-calibration but before imaging, CHIPS uses its own internal instrument model to estimate and propagate uncertainty.	

The method involves four major steps: (1) Grid and weight time-ordered visibility channels onto a $uvw$-cube using the primary beam model, (2) compute the least squares spectral (LSS) transform along the frequency dimension to obtain the best estimate of the line-of-sight spatial sky modes (this technique is comparable to that used by \eppsilon), (3) compute the maximum-likelihood estimate of the power spectrum, incorporating foregrounds and radiometric noise,  averaging $k_x$ and $k_y$ modes into annular modes on the sky, $k_\bot$; (4) compute the uncertainties and covariances between power estimates. The first step is the most computationally-intensive, requiring processing of all the measured data. The principle departure point for CHIPS from \eppsilon{} is in the much finer resolution of the $uv$ grid.  Using an instrument model, CHIPS calculates the covariance between $uv$ samples as a function of frequency.  Since the beam and $uv$ sampling function are both highly chromatic, extra precision in this inversion is thought to be highly beneficial. After a line of sight transform similar to that used by \eppsilon{}, this covariance information is inverted to find the Fisher Information, the maximum likelihood power spectrum, and covariances between measurements.  The maximum likelihood estimate of the power in each $k_\bot,k_\parallel$ mode is shown in the right column of Figure \ref{fig:pspec_compare} and averaged in spherical bins in Figure \ref{fig:1D_pspecs}. This last averaging step includes an additional weighting by the known power spectrum of a confused foreground in a process described in more detail for these data by \chipscite{}. The power spectra have been split into three redshift ranges of $\Delta z\sim$0.5. Though well above the predicted cosmological signal level, the measurements are notably consistent with noise across a wide range of $k$. 

\subsection{Power Spectrum \#3: Empirical Covariance}
\label{sec:empirical_cov}

The \empirical{} power-spectrum estimation method computes a 1D power spectrum using a quadratic estimator formalism. The method and its application to this data is described in more detail by \dilloncite{}; here we provide a short description.

The quadratic estimator method of \cite{Liu:2011p8763} treats foreground residuals in maps as a form of correlated noise and simultaneously downweights both noisy and foreground-dominated modes, keeping track of the extra variance they introduce into power spectrum estimates. This technique can be computationally demanding but using an acceleration techniques described by \cite{Dillon:2013p10497}, has been applied to the previous MWA 32T results of \cite{Dillon:2014p9788} while a very similar technique, working on visibilities rather than maps, was used for the recent PAPER 64 results of \cite{2015arXiv150206016A}.  \dilloncite{} build on these methods to mitigate errors introduced by imperfect mapmaking and instrument modeling through empirical covariance estimation, assuming all data covariance is sourced by foregrounds.

\empirical{} takes as input FHD calibrated images with foregrounds subtracted as well as possible, split into even and odd time-slices and averaged over many observations. From these cubes, it estimates the frequency-frequency foreground residual covariance in annuli in $uvf$ space, assuming that different uv cells have uncorrelated foreground residuals. This assumption, similar to that made by CHIPS, allows the combined foreground and noise covariance to be inverted directly. The resulting power spectrum is shown in Figure \ref{fig:1D_pspecs} for direct comparison with the CHIPS result. 


\subsection{Benefits of Comparison}
\label{sec:benefits_of_comparison}


One benefit from having multiple pipelines is the freedom to investigate  different optimization axes.  The design of the \eppsilon{} power spectrum estimator emphasizes speed and relative simplicity, choices  motivated by the need to understand the effect, on the power spectrum, of processing decisions such as observation protocol, flagging, and calibration. Using \eppsilon{} we have discovered and corrected multiple systematic effects. Primarily those of a spectral nature which were not obvious in imaging but quite apparent in the 2D power spectrum. With the ability to quickly form power spectra on different sets of data, \eppsilon{} has been an important tool for selecting sets of high quality data. 

In contrast, CHIPS starts from time-ordered data and in its calculations emphasizes a more full accounting of instrumental and residual foreground covariance. Not only does this higher resolution covariance calculation provide a more accurate accounting of the instrumental window function on the power spectrum, but it also allows for more precise weighting schemes based on knowledge of the statistical properties of the residual foregrounds. This is useful when making 1D power spectra where foreground-like modes can be down-weighted in the average. 


\section{Comparison Discussion}
\label{sec:results}
%TODO XXX put FHD and RTS, and W/ Foregrounds and subtracted on the figure
Inspecting a comparison of the images and power spectra reveals several common features. Images before and after foreground subtraction are shown in Figure \ref{fig:image_compare}, presented in the natural weighting used by the power spectrum estimators without application of any deconvolution.  Putting the same 3 hours of MWA data\footnote{NB: To simplify data handoff for the RTS to \eppsilon{} step only the 30 minute zenith integration was used for that pathway.} into each pipeline, we inspect output images before and after foreground subtraction. The pre foreground-subtracted (sometimes called the ``dirty'' image) have the largest difference with slight differences in point spread function leading to high residuals around bright sources. These are well modeled in the subtraction step but without deconvolution subtract poorly in the image plane.  The foreground subtracted images (sometimes called ``residual'' images) show a much closer agreement both around the subtracted sources and in the large scale structure. Large scale structure is more difficult to distinguish . Inspection of the snapshot images before averaging in time and frequency revealed that the structure is constant across both time and frequency, which suggests real galactic emission rather than sidelobes or aliasing.  

% TODO XXX
%what else to say about the image comparison? maybe some basic stats about the fluxes and fractional error.


%The effectiveness of foreground subtraction is highly dependent on the choice of sources included in the model: too few sources subtracted leaves an excess of power which must be removed as extra free parameters in the covariance step, too many sources leaves open the possibility of mis-subtraction as the number of sources and amount of sky covered increases. In the middle row we have locked both pipelines to the RTS's smaller but more readily diagnostic catalog of 300 sources.  This subtraction step decreases the image rms by half and results in a somewhat flatter difference image.  In the bottom row we have allowed each system to select from its internal catalog based on nominal operating parameters, for the FHD this means the number of sources increases to 1000 and results in a further decrease in image rms by \~33\% and a smaller 20\% decrease in the \emph{difference} with the RTS image.   This is the residual data set which is passed to the power spectrum estimation portions of the pipelines.

 %  The primary way in which the images in Figure \ref{fig:image_compare} differ is that both consistently present a significant amount of large scale power which, while visually similar in some respects, differs at the 50 to 100\% level.  The power is generically described as several large ``islands'' of power (both positive and negative) and which, in the difference image, give the appearance of beginning to dissipate as more sources are subtracted.  
%\begin{figure}[htbp]
%\begin{center}
%\includegraphics[width=\columnwidth]{figures/MWA128_radial_uv_density.png}
%\caption{\label{fig:density_plot} The radial density of samples in the uv plane is dominated by short spacings but the calibration model is most accurate on the longer spacings.  The MWA is optimized to be sensitive to degree-scale epoch of reionization structure, as we see from the cumulative fraction of weights (black, right hand scale), some 50\% of the baselines are shorter than 120 wavelengths and a large fraction (black, left hand scale) are inside of 50 wavelengths.  At the same time, power from Galactic foregrounds is known to dominate on these short spacings. Until a model of Galactic emission, of sufficient precision for calibration purposes, is available, baselines below $\sim$40 wavelengths are excluded from the calibration operation.  Though data from these baselines are still included in the imaging and power spectra presented here, the large-scale results stand to improve significantly from from adoption of diffuse emission models into the calibration. }
%\label{default}
%\end{center}
%\end{figure}


%The residual, after subtraction of many hundreds of sources, tells a fairly consistent story of a significant amount of large scale power remaining, though the two imagers disagree somewhat on the exact arrangement.  The primary question is whether any large-scale structure is ``real'', rather than some mis-calibration or other artifact that affects the large number of short baselines. Calibration errors in a traditional interferometer having uniformly distributed baselines reveal themselves as side lobes around bright point sources; similar errors on the core-heavy MWA reveal themselves as artifactual large-scale power which is more difficult to distinguish from true emission.
%
%One possible origin of disagreement follows from a consideration of the physical layout of the MWA and the  approach to calibration used in both imagers. The MWA is optimized to be sensitive to degree-scale epoch of reionization structure \citep{Beardsley:2013p9952}; reconstruction of the large scales is crucial to subtracting modeled foregrounds at small $k$, where reionization is brightest.    As we see from radial distribution of $uv$ weights in Figure \ref{fig:density_plot},  50\% of the baselines are shorter than 120 wavelengths (0.5\arcdeg scales) and a large fraction are highly localizes inside of 50 wavelengths (1.1\arcdeg scales).  At the same time, power from Galactic foregrounds is known to dominate on these scales. Until a model of Galactic emission, of sufficient precision for calibration purposes, is available, baselines below $\sim$40 wavelengths have been excluded from the calibration process, though data from these baselines are still included in the imaging and power spectra presented here, the large-scale results stand to improve significantly from from adoption of diffuse emission models into the calibration.


\subsection{Power Spectra}

Application of our two independent power spectrum estimators to our two calibration and foreground subtraction pipes gives us a total of four different power spectra (Figure \ref{fig:pspec_compare}).  Each power spectrum estimator has been developed to target the output from a ``primary'' calibration and foreground subtraction process --the diagonal elements of Figure \ref{fig:pspec_compare}-- and have been highly optimized to that up-stream source of data.  The off-diagonal power spectra were created using auxiliary links which import the data and the metadata produced by the foreground subtraction step.  Since they are less highly optimized, lacking as they do the advantage of a close working relationship, these pathways represent an upper limit on the variance to be expected from small analysis differences but allow us to look for effects common to foreground subtraction or to power spectrum method.


Properties shared by all are the large amount of power at low $k_{\parallel}$ roughly at an amplitude of $10^{15}$ mK$^2$/Mpc$^3$ and approximately flat in $k_{\perp}$ with its ``wedge'' shaped linear dependance on baseline length.  The wedge is due to the inherently chromatic response of a wide field instrument to smooth spectrum foregrounds; sources entering far from the phase center appear as bright pixels at higher $k_\parallel$ with sources on the horizon at the edge indicated by Figure \ref{fig:pspec_compare}'s  solid black line. The solid and dotted lines in the figure indicate the upper boundaries of power from sources at the horizon and at the beam half power point, respectively.  With the exception of some instrumental features foreground power is well isolated within this expected boundary. This emission is also visible in the image cubes as side-lobes extending from outside of the imaged area which move as function of frequency.  Observations recorded when the Galactic plane is near the horizon have a much larger wedge component and have been excluded from this analysis. See \citet{2015arXiv150207596T} for a detailed discussion of the foreground contributions to the power spectra in this data.
%TODO fix Nithya's cite
The two main instrumental systematics are horizontal striping due to missing or poorly calibrated data at the edges of regular coarse passbands and vertical striping due to spectral variation near uneven $uvf$ sampling. The former can be minimized by careful calibration of the passband, the latter by $uv$ rotation synthesis and by accounting for covariance between $uvf$ samples. 
\begin{figure}[htbp]
\begin{center}
\includegraphics[width=\textwidth]{figures/MWAPipeline_compare_1d_kperp}
\caption{Horizontal cut sampling the $k_\parallel = 0$ mode of the 2D power spectra shown in Figure \ref{fig:pspec_compare} indicating good agreement over most k modes.}
\label{fig:1d_kperp}
\end{center}
\end{figure}
The most noticeable difference between the different pipeline paths is in the noise level of the so-called ``window'' above the horizon and below the first coarse passband line (between 0.1 and 0.3 $k_\parallel$ and 0.01 and 0.05 $k_\perp$). FHD to \eppsilon{} is the only path to have a noise-like window in the 2D space, with a number of points dipping below zero. Similarly, both RTS power spectra have a few areas without positive bias, though only at much higher $k$s.  One commonality between all power spectra with positive bias is the amplitude of the coarse passband lines.
%The most noticeable difference between foreground removal methods is in the shape of the power spectrum at $k_\parallel=0$.  Where power spectra using data from FHD have a fairly uniform increase in power with decreasing $k_\perp$ those using RTS data have a roughly flat spectrum which increases dramatically in the few bins below $k_\perp<.002$ or below 20 wavelengths.  We note from Figure \ref{fig:density_plot}) that the number of baselines drops precipitously below 20 wavelengths and draw the preliminary conclusion there must be some difference in how RTS treats the very shortest baselines. However, the fact that the effect is found in power spectra derived from time-ordered visibilities as well as image cubes, suggests that the effect is likely not due treatment of gridding or image reconstruction but rather in calibration or foreground subtraction steps.


The major difference between the power spectrum methods is in the calculation and minimization of $uvf$ covariance.   CHIPS aims to make a more accurate mathematical treatment of the covariance but to do so it must take on more of the instrument modeling. Meanwhile, \eppsilon{} leaves the modeling to the foreground subtraction step and assumes that, to first order, covariance has been minimized by an  additional down-weighting by the primary beam of the instrument.  The practical outcome of this difference is that CHIPS can only take full advantage of the covariance between data points in the full 1D averaged power spectrum and is not as optimized for making 2D power spectra as \eppsilon{}.  The 1D power spectra shown in Figure \ref{fig:1D_pspecs}, indicate a good number of points which are consistent with zero.

The final analysis step is to average into 1D power spectra along shells of constant $k$. These are shown in Figure \ref{fig:1D_pspecs} for three of the four analysis tracks\footnote{The shorter RTS->\eppsilon integration is excluded because it doesn't have the same sensitivity and complicates the comparison.} shown in Figure \ref{fig:pspec_compare} and with the addition of \dilloncite{} points. Here an interesting comparison can be made between two alternative covariance weightings; CHIPS down-weights by an a-priori statistical model of confused foregrounds while \empirical{} makes an empirical estimate of the covariance in the data. Both down-weighting schemes  decrease the amount of power leaking into the lowest $k$ modes, though at low $k$ CHIPS finds somewhat higher power than the Dillon scheme.  That the two methods do arrive at similar answers suggest that much of the residual covariance can be modeled as foreground rather than instrumental systematic. All points and limits are a factor of a few above the estimated sensitivity level corresponding to a three hour integration, calculated using the 21CMSENSE sensitivity code\footnote{\url{github.com/jpober/21cmsense/}} \cite{Pober:2014p10390}.

%Thus one of the largest differences is in the amount of correlation along the vertical, or line-of-sight, direction.  Both CHIPs and \eppsilon{}, when applied to their  primary foreground subtraction strategy (FHD for \eppsilon{} and RTS for CHIPS), have minimal line-of-sight covariance at low $k_\perp$ where frequency to frequency variation in $uv$ sampling is small. At high $k_\perp$ \eppsilon{}'s simplistic Fourier Transform reveals the large residual correlation between different $uv\eta$ cells caused by the fact that baseline length changes quickly with frequency.  \eppsilon{} has so far not accounted for covariance choosing speed over accuracy on long baselines.


%The final analysis step is to average the 2D power spectra into 1D radial averages, shown in Figure \ref{fig:1D_pspecs} for \empirical{} and CHIPS applied to FHD. In three hours of data the two independent methods demonstrate similar, largely noise limited, measurements of the power spectrum.  The red points are weighted by an empirical estimate of foreground-like covariance and are further described in \dilloncite{}.  The black points are computed using the CHIPS estimator and then further weighted by a model of the confused foregrounds and are further described in \chipscite{}. Both down-weighting schemes  decrease the amount of power leaking into the lowest $k$ modes, though at low $k$ CHIPS finds somewhat higher power than the Dillon scheme. This is not inconsistent with the differences in method. CHIPS limits its down-weighting to a model of residual foreground covariance caused by a stochastic background of confused point sources while \empirical{} uses a model of covariance derived from the data itself (though limited in free parameters so as to minimized signal loss). That the two methods do arrive at similar answers suggest that much of the residual covariance can be modeled as foreground rather than instrumental systematic.     Any remaining excesses in this plot are thought to be consistent with a fairly aggressive inclusion of the parts of $k$-space near to the wedge --in this case points up to 0.02Mpc$^{-1}$ away from the horizon (the solid black line in Figure \ref{fig:pspec_compare}) were included-- and known systematics like cable reflections. At high $k$ values both methods are in good agreement with each other and with the theoretical noise level; given the data included we expect a $\sqrt{2}$ difference in the noise level.  

%Using the speedup provided by \eppsilon, many iterations of ``preview'' power spectra were used to view the effect of calibration and flagging choices on the power spectrum. For example the wide-field effects, described in detail by \cite{2015arXiv150207596T}, are clearly visible in power spectra computed by \eppsilon{} and are seen to be stronger for certain configurations of pointing and sky. Removing these portions of the data eliminated a substantial amount of bleed from the wedge into the window.  Using this and other jackknife selections we arrived at a refined data FHD image cube which was then carried into the \empirical cov analysis resulting in the power spectra shown in Figure \ref{fig:1D_pspecs}.   Though well above the predicted signal level the 2$\sigma$ error bars are mostly consistent with noise.   Residual excesses --particularly near low $k$s--  are consistent with a fairly aggressive inclusion of points near to the wedge, in this case points up to 0.02$Mpc^{-1}$ away from the horizon (the solid black line in Figure \ref{fig:pspec_compare})were included.





\begin{figure*}[h!]
\begin{center}
\includegraphics[width=0.8\textwidth]{figures/MWA_PS_compare/MWA_PS_compare.png}
\caption{Power spectra computed using two foreground subtraction methods and two power spectrum estimation methods on the data shown in Figure \ref{fig:image_compare}, the 3D power spectrum has been computed in full 3D and then averaged cylindrically.  In the top row data have been calibrated and foreground subtracted using the Fast Holographic Deconvolution method, in the bottom row by the MWA Real Time System.  In the left column, power spectra have been estimated with \eppsilon, which emphasizes speed and full error propagation, in the right column, CHIPS corrects more correlation between $k$ modes.  All spectra display the now well-understood ``wedge''-shaped foreground residual and horizontal stripes caused by evenly spaced gaps in the instrument pass-band.  \empirical{} 2D power spectra were not included in the \dilloncite{} analysis and so are excluded here. \label{fig:pspec_compare}}
\end{center}
\end{figure*}


%comparison
% difference between RTS and CHIPS, comparison of error plots 
% snapshots and maybe polarization.
% Cath to fix horizon line. Settled on 110 degrees.
% k_perp, Cath's data are edge points.
% 1D curve from eppsilon 

\begin{figure*}[h!]

\includegraphics[width=\textwidth]{figures/MWA_PS_Compare/MWAPipeline_compare_1d_radial_logbryna.png}
\caption{Power spectra averaged along shells of constant $|k|$. In three hours of data, four different methods demonstrate similar, largely noise limited, measurements of the power spectrum. Note that of the four pathways shown in Figure \ref{fig:pspec_compare}, only three are included here. We have also included an additional 1D estimate made with the Dillon et. al inverse covariance method. In all methods, save \eppsilon{}, power and errors have been estimated with some variant of Many of the features visible in the 2D plots are also visible here. Points at or below $k<0.3$ are dominated by the foreground wedge. These are accessible only if the estimated power is down-weighted by the foreground residual as it is in all methods shown here, save \eppsilon{} where the points have been excluded. The black curve indicates the 1$\sigma$ bounds of points dominated by noise.  Power levels for typical theoretical models are typically in the 5 to 10 mK$^2$ range across these $k$ modes.
\label{fig:1D_pspecs}}
%TODO XXX Add theory line?
%TODO XXX update sensitivity curve with updated Tsys
\end{figure*}
%\begin{figure*}[h!]
%\begin{center}
%\includegraphics[width=\textwidth]{figures/1dDeltaSqComparisonFHD.pdf}
%\caption{Here we have power spectra averaged along shells of constant $|k|$ where foregrounds have been further down-weighted by inverse covariance after calibration and foreground subtraction by FHD. In three hours of data, two independent methods demonstrate similar, largely noise limited, measurements of the power spectrum.  A theoretical model (blue, \cite{Barkana:2009p1454}) sets the scale.  The red points are weighted by an empirical estimate of foreground-like covariance and are described in \dilloncite.  The black points are computed using the CHIPS estimator and then further weighted by a model of the confused foregrounds and are further described in \chipscite. The action of both foreground down-weighting schemes is to decrease the amount of power leaking from the very lowest $k$ modes. At low $k$ CHIPS finds somewhat higher power, as discussed in the text this is not inconsistent with the differences in the weight models   The very high CHIPS point  is dominated by a very small amount of data, but is included for completeness.  At high $k$ values both methods are in good agreement with each other and with the theoretical noise level (this line has been omitted for clarity); given the data included we expect a $\sqrt{2}$ difference in the noise level.  Any remaining excesses in this plot are thought to be consistent with a fairly aggressive inclusion of points near to the wedge --in this case points up to 0.02Mpc$^{-1}$ away from the horizon (the solid black line in Figure \ref{fig:pspec_compare}) were included-- and known systematics like cable reflections.\label{fig:1D_pspecs}}
%\end{center}
%\end{figure*}


\section{Conclusions}
\label{sec:conclusion}
      A data analysis pipeline is necessarily built on a complex software framework which is only imperfectly described in prose and is susceptible to human error.  Comparison between independently developed analysis paths, each with their own strengths and limitations is essential to placing believable constraints on the Epoch of Reionization. The ongoing comparison between independent MWA pipelines has revealed a number of issues both systematic (related to our understanding of the instrument or foregrounds) and algorithmic (optimizing our use of this knowledge) which we will briefly mention here.
      
\begin{itemize}
%\item \emph{ power spectrum method}
%TODO discuss significance of differences between power spectra
%TODO Editing to HERE

\item \emph{ cable reflections}

One oft debated aspect of calibration is the number of free parameters allowed into the spectral dimension. Individual calibration of each channel independently allows the greatest flexibility but has the consequence of possibly adding or subtracting to the spectral line reionization signal.  Both calibration pipelines begin by calibrating each channel and then averaging over a number of axes.  The RTS fits a low order polynomial, piecewise, to each of the 24 1.28MHz sub-band solutions, while FHD fits a similar order polynomial to the entire  band's calibration solution.  Inspection of power spectra calibrated using the FHD scheme revealed  previously unknown spectral features corresponding to reflections on the analog cables at the -20dB level (~1.5\%). FHD calibration now includes a fit for these reflections and the feature is no longer visible. These features are fully covered by the RTS fit (which uses of order 10 times as many free parameters as FHD).

\item \emph{full forward modeling for absolute calibration and signal loss}

During the comparison process, one way in which all pipeline results differed from each other is in the overall amplitude of the power spectrum scale. To agree the overall flux calibration, weightings, and Fourier conventions must all be well understood.  Perhaps the most important factor is assessment of signal loss.  Unintential or unavoidable down-weighting or subtraction of reionization signal could occur at multiple stages such as bandpass calibration, $uvf$ gridding, or inverse covariance weighting. This loss is best calibrated via forward modeling of a simulated reionization signal and in the process provides verification of the overall power spectrum scale.  Such simulations have been used to verify the various steps in the FHD-\eppsilon{} pipeline and by stepping through the pipeline at each major operation have been shown to be self-consistent (see \eppsiloncite{}) and suitable for calibration of the other pipelines.
\end{itemize}

  We must stress that without the ability to compare between independent pipelines, most of these effects would have gone un-detected or mis-diagnosed as algorithmic deficiencies and have persisted into the final result. In addition to pipeline redundancy, forward modeling can provide some important checks, indeed absolute calibration of FHD using a model is described in \eppsiloncite{}, however if a model is relied on exclusively algorithmic accuracy will be limited to the accuracy of the model.


In this overview paper we have provided a top level view of foreground subtraction and power spectrum estimations methods described more completely in companion papers \eppsiloncite{}, \chipscite{}, and \dilloncite{} and provided a basis for an apples-to-apples comparison.  In this comparison we see that both foreground subtraction methods are able to reliably remove about 50\% of the power with a fairly simplistic model but that the reconstruction of the residual large scale power depends heavily on small differences in calibration and imaging algorithms which ultimately limits the accuracy of the reconstruction.  In a similar way we use the difference between two independent pipelines to reveal effects in the power spectrum which seem to be common to the calibration and foreground subtraction step, and those which appear to be common to the sky itself and on a believably consistent scale.  Though none of the power spectra are identical, the degree of agreement and the success at making nearly noise limited measurements allows us to draw conclusions about the relative quality of different selections of data. Believing in our pipeline to first order allows us to declare that bad data is truly bad and not evidence of an underlying software or algorithmic problem.  Using our validated pipeline to make quick estimates of the power spectrum in different selections of data we were able to select a high quality set, with a well understood calibration, for application of the empirical  covariance technique and generate a noise limited measurement. 

The 1D power spectrum presented here and in \dilloncite{} is roughly 500 times deeper then the previous MWA power spectrum \citep{Dillon:2014p9788} which was done using roughly the same amount of integration time but only 32 of the present 128 tiles.  Future work will focus on refining calibration and weighting schemes to more accurately reconstruct large scale power and building on deeper integrations using data collected in recent observing campaigns.




\acknowledgments

This work was supported	 by the U. S. National Science Foundation (NSF) through award AST--1109257. DCJ is supported by an NSF Astronomy and Astrophysics Postdoctoral Fellowship under award AST--1401708. JCP is supported by an NSF Astronomy and Astrophysics Fellowship under award AST-1302774. This scientific work makes use of the Murchison Radio-astronomy Observatory, operated by CSIRO. We acknowledge the Wajarri Yamatji people as the traditional owners of the Observatory site. Support for the MWA comes from the U.S. National Science Foundation (grants AST-0457585, PHY-0835713, CAREER-0847753, and AST-0908884), the Australian Research Council (LIEF grants LE0775621 and LE0882938), the U.S. Air Force Office of Scientific Research (grant FA9550-0510247), and the Centre for All-sky Astrophysics (an Australian Research Council Centre of Excellence funded by grant CE110001020). Support is also provided by the Smithsonian Astrophysical Observatory, the MIT School of Science, the Raman Research Institute, the Australian National University, and the Victoria University of Wellington (via grant MED-E1799 from the New Zealand Ministry of Economic Development and an IBM Shared University Research Grant). The Australian Federal government provides additional support via the Commonwealth Scientific and Industrial Research Organisation (CSIRO), National Collaborative Research Infrastructure Strategy, Education Investment Fund, and the Australia India Strategic Research Fund, and Astronomy Australia Limited, under contract to Curtin University. We acknowledge the iVEC Petabyte Data Store, the Initiative in Innovative Computing and the CUDA Center for Excellence sponsored by NVIDIA at Harvard University, and the International Centre for Radio Astronomy Research (ICRAR), a Joint Venture of Curtin University and The University of Western Australia, funded by the Western Australian State government.
\bibliography{bibliography/library}

\end{document}

