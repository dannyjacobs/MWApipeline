%\documentclass[10pt,flushrt,preprint]{aastex}

%\documentclass[preprint2]{aastex}
\documentclass[twolcolumn,iop]{emulateapj}

\usepackage{graphicx}
\usepackage[space]{grffile}
\usepackage{latexsym}
\usepackage{amsfonts,amsmath,amssymb}
\usepackage{url}
\usepackage[utf8]{inputenc}
\usepackage{fancyref}
\usepackage{hyperref}
\hypersetup{colorlinks=false,pdfborder={0 0 0},}
\usepackage{textcomp}
\usepackage{longtable}
\usepackage{multirow,booktabs}
%\usepackage{aastex_hack}

\usepackage{natbib}

\newcommand{\truncateit}[1]{\truncate{0.8\textwidth}{#1}}
\newcommand{\scititle}[1]{\title[\truncateit{#1}]{#1}}


%% preprint2 produces a double-column, single-spaced document:

%% \documentclass[preprint2]{aastex}

%% Sometimes a paper's abstract is too long to fit on the
%% title page in preprint2 mode. When that is the case,
%% use the longabstract style option.

%% \documentclass[preprint2,longabstract]{aastex}

%% If you want to create your own macros, you can do so
%% using \newcommand. Your macros should appear before
%% the \begin{document} command.
%%
%% If you are submitting to a journal that translates manuscripts
%% into SGML, you need to follow certain guidelines when preparing
%% your macros. See the AASTeX v5.x Author Guide
%% for information.


%% You can insert a short comment on the title page using the command below.

\slugcomment{tbd journal: ApJ}

%% If you wish, you may supply running head information, although
%% this information may be modified by the editorial offices.
%% The left head contains a list of authors,
%% usually a maximum of three (otherwise use et al.).  The right
%% head is a modified title of up to roughly 44 characters.
%% Running heads will not print in the manuscript style.

\shorttitle{ MWA Epoch of Reionization Project: Data and Results}
\shortauthors{D. Jacobs}

%% This is the end of the preamble.  Indicate the beginning of the
%% paper itself with \begin{document}.


%% Use \author, \affil, and the \and command to format
%% author and affiliation information.
%% Note that \email has replaced the old \authoremail command
%% from AASTeX v4.0. You can use \email to mark an email address
%% anywhere in the paper, not just in the front matter.
%% As in the title, use \\ to force line breaks.
\def\eppsilon{{\it $\varepsilon$ppsilon}}
\def\empirical{DILLSPEC}
\def\chipscite{Trott et al 2015}
\def\eppsiloncite{Hazelton et al 2015}
\def\dilloncite{Dillon et al 2015 }



%% \definenote[thanks][conversion=set 2]

\begin{document}

%% LaTeX will automatically break titles if they run longer than
%% one line. However, you may use \\ to force a line break if
%% you desire.

\title{Murchison Widefield Array Epoch of Reionization Project: Validation of power spectrum strategy}


%% Author list
\include{mwa_eor_collab_latex}



%XXX check redshift range 
\begin{abstract}
We present an overview and comparison of current Murchison Widefield Array 21\,cm Epoch of Reionization results for the purpose of validating statistical detections of cosmological Hydrogen at redshifts between 7.5 and 10. Detection of the weak cosmological signal in the presence of bright foregrounds requires a very high spectral dynamic range and integration of large amounts of data. Doing so with wide-field, broadband radio arrays like the MWA has necessitated the development of new algorithmic approaches which have been wrapped into equally new processing pipelines and then applied to thousands of hours of data. Validation of  correct pipeline operation is essential to producing believable results. One time-tested approach, demonstrated here for 21 cm cosmology, is the development and comparison of results from independent pipelines. Parallel analysis is complimentary to pure simulation where the result is only as accurate as the model.  This paper provides a top level comparison between multiple, independent, data calibration and reduction pipelines through to power spectrum limits.  The comparison is made at both the imaging and power spectrum levels, addressing the differences in calibration, imaging and power spectrum calculation. Comparing images, we see good agreement between the large scale structures where reionization power is expected to be brightest, with the differences much smaller than the residual remaining after foreground subtraction. Features common to all power spectra show the continued significance of wide-field effects, while small differences are primarily due to variations in power spectrum method. One key difference, the choice of weighting in the calculation of the power spectrum limits, is a tradeoff between foreground suppression and signal loss. Here we use multiple weighting schemes, spanning this tradeoff space, to make power spectrum upper limits which we find to be in good agreement with each other and the expected noise.  

\end{abstract}




%% Keywords should appear after the \end{abstract} command. The uncommented
%% example has been keyed in ApJ style. See the instructions to authors
%% for the journal to which you are submitting your paper to determine
%% what keyword punctuation is appropriate.

%\keywords{globular clusters: general --- globular clusters: individual(NGC 6397, NGC 6624, NGC 7078, Terzan 8}

\bibliographystyle{apj_w_etal}


\section{Introduction} 
  Study of primordial Hydrogen  in the early universe via 21\,cm radiation has been forecast to provide a wealth of astrophysical and cosmological information.   Hydrogen is the principal product of big bang nucleosynthesis and is neutral over cosmic time from recombination until reionized by the first batch of UV emitters (stars and accretion disks). While neutral it is visible in the 21\,cm radio line, which is both optically thin and spectrally narrow, making possible full tomographic reconstruction of a very large fraction of the cosmological volume.  Reviews of 21 cm cosmology, astrophysics and observing can be found in \cite{Morales:2010p8093,Furlanetto:2006p2267,Pritchard:2012p9555,zaroubi2013epoch}.
  
Direct detection of HI during the Epoch of Reionization (cosmological redshifts $5<z<13$) is currently the goal of several new radio arrays. The LOw Frequency ARray \citep[LOFAR;][]{Yatawatta:2013p9699}, the Donald C. Backer Precision Array for Probing the Epoch of Reionization \citep[PAPER][]{Parsons:2014p10499} and the Murchison Widefield Array (MWA; \cite{Tingay:2013p9022,Bowman:2013p9950}) are all currently conducting long observing campaigns.



The analysis of the resulting data presents several challenges. The signal is faint; initial detection is being sought in the power spectrum with thousands of hours (multiple seasons) of integration required. This faint spectral line signal sits atop a continuum foreground four orders of magnitude brighter. At the same time, the instruments are fully correlated phased arrays with wide fields of view that strain the conventional mathematical approximations of radio astronomy practice. The methods used to arrive at a well calibrated, foreground-free, estimation of the power spectrum are all under development in the sense of the algorithms as well as the implementation.  


The path from observation to power spectrum can be roughly divided into two parts: removal of foregrounds and estimation of power spectrum. 
Methods for estimating the power spectrum, particularly those which minimize the effects of foregrounds, have been studied and implemented by \citet{Morales:2006p1870,Morales:2012p8790,Dillon:2013p10497,Dillon:2014p9788,Liu:2011p8763,Liu:2014p10462,Liu:2014p10463,Trott:2012p10466}. Essential elements include using knowledge about the instrument and foregrounds to minimize covariance, applying an optimal quadratic estimator to make a minimal error estimate, and studies of effects related to including the spectral dimension in the Fourier transform.  One significant problem studied has been minimizing the impact of any residual foregrounds by down-weighting or minimizing correlation with contaminated band powers. In this paper we compare power spectra calculated using a range of methods. 

Most power spectrum analyses require removal of bright foregrounds to some level.  Recently, two sorts of foreground removal have been suggested: methods which exploit detailed knowledge of foregrounds and those which are relatively agnostic. Among the latter, several authors have described methods for fitting and removing smooth spectrum foregrounds from image cubes  \cite{Morales:2006p1903,Bowman:2009p7816,Liu:2009p4762,Liu:2011p8763,Chapman:2013p10379,Dillon:2013p10497,Yatawatta:2013p9699}. These methods have been demonstrated to robustly remove foregrounds near the field center but are less effective for sources far from the central lobe of the primary beam.  A second class of agnostic methods is the delay/fringe-rate filtering approach \citep{Parsons:2012p8896,Liu:2014p10462,Liu:2014p10463}, which has been applied to data from PAPER \citep{Parsons:2014p10499}.  Applying time and frequency domain filters to the time ordered data, this technique uses a small amount of knowledge about the instrument to filter modes likely to be dominated by foregrounds.  This method removes smooth spectrum foregrounds across the entire sky and is comparatively robust in the face of uncertainty about the instrument at the cost of losing some sensitivity.  Meanwhile, full forward modeling and subtraction of sky model such as that implemented for LOFAR (see e.g. \cite{Jelic:2008p2130,Yatawatta:2013p9699}), requires a much higher fidelity model of the instrument and the sky \citep{Datta:2010p8781,Vedantham:2012p10297}.


The MWA foreground removal approach leverages the array's optimization for imaging to directly subtract known foregrounds in addition to the full range of treatments of residual foregrounds, including foreground avoidance and foreground suppression.  If successful, direct subtraction opens the most sensitive power spectrum modes substantially improving the ability of early measurements to distinguish between reionization models \citep{Beardsley:2013p9952,Pober:2014p10390}. Recent work towards the goal of foreground subtraction includes better algorithmic handling of wide field imaging effects \citep{Tasse:2012p9459,Bhatnagar..2013ApJ,Sullivan:2012p9457,Ord:2010p8442}, and continually improving catalogs of sky emission \citep{deOliveiraCosta:2008p2242,Jacobs:2011p8438,Hurley-walker:2014p45,2014AAS...22342101M}. Ongoing operation of the next generation low frequency arrays --LOFAR, PAPER and MWA are all in their  third or fourth year of operation-- continues to push the refinement of instrumental models (e.g. the work of \cite{2015RaSc...50..614N} in mapping the primary beam with satellites) and improve the accuracy of model subtraction.  At the same time, more complete surveys of foregrounds are currently under way. These include the MWA GLEAM\footnote{GLEAM: GaLactic and Extragalactic All-sky MWA} survey \citep{2015PASA...32...25W}  and the LOFAR MSSS\footnote{MSSS: Multi-frequency Snapshot Sky Survey}.   

In turn, efforts with these currently operational experiments are having a major influence on how future, larger, EoR experiments will be designed and conducted.  Primary among these future experiments will be programs using the low frequency Square Kilometer Array (\cite{2014aska.confE...1K}) and the Hydrogen Epoch of Reionization Array \citep[HERA][]{Pober:2014p10390}.  Specifically, the MWA is one of three official precursor telescopes for the SKA and the only one of the three fully operational for science.  The low frequency SKA will be located at the MWA site in Western Australia, giving the MWA special significance.

Given the challenges of using newly developed methods to reduce data from a novel instrument to make a low sensitivity detection, it is reasonable to consider the question of how one knows one is getting the ``right'' answer.  One option is to generate, as accurately as possible, a detailed simulation of the interferometer output and then input that to the pipeline under test.  Such forward modeling is an essential tool for checking correct operation of portions of the pipeline, however the model will always be an imperfect reflection of reality, leaving open multiple interpretations of any differences between model and data.  Forward modeling the instrument response is also difficult to divorce from the analysis pipeline being tested; often the same software doing the analysis is used to perform the simulations. A second option, and the focus of this paper, is comparison between multiple independent pipelines.% Development of a completely independent instrumental simulation is the subject of ongoing work \citep[see e.g..][]{2015arXiv150207596T}.  The second option is more pragmatic; compare the results of multiple independent pipelines operating on real data.
In this paper we apply several MWA pipelines --described in detail in companion papers-- comparing their power spectrum outputs to assess the accuracy of their limits on 21\,cm emission during reionization.  Within the MWA collaboration efforts have centered around multiple independent paths from raw data to a power spectrum.  As described in Figure \ref{fig:pipes}, these pipelines are generally divided into a component which performs calibration, foreground subtraction and imaging, and one which computes the power spectrum.  During development, each power spectrum code was paired with a ``primary'' foreground subtraction method.  Though the main results come from these primary paths (as depicted by the thin lines in Figure \ref{fig:pipes}). These results are then checked by cross-connecting the pipelines at intermediate points, with the goal of separating effects common to specific codes or algorithms.

The analysis presented here is on three hours of data, one of 400 nights which have been collected as part of the MWA 21\,cm observing program; 150 nights are thought to be necessary for a detection of typical models \citep{Beardsley:2013p9952}. The 400 nights span multiple tunings, pointings, and observing conditions. Here the analysis has been limited to one representative night with the goal of validating our instrument model, sky model, and power spectrum methods on a well understood data set. 

% a representative sample of the observing program which is repeated nightly. The amount of data required to detect a fiducial 21\,cm emission model is thought to be around 450 hours \citep{Beardsley:2013p9952} or about 150 nights.  The MWA 21\,cm program has recorded over 1000 hours of data spanning multiple fields, tunings, and observing conditions. A night is the smallest complete amount of data, larger amounts of data are just repeated measurements, and is enough to build confidence in the accuracy of our pipelines and establish the framework of independent pipeline comparison.




In section \ref{sec:observing} we summarize the observing strategy used to collect our data, section \ref{sec:pipelines} explains our multiple pipelines and comparison strategy. In section \ref{sec:results} we show comparisons of images, 2D diagnostic power spectra and 1D power spectrum limits, and conclude in section \ref{sec:conclusion} with an overview of lessons learned from the comparison process and directions of future work .



\section{Observing}
\label{sec:observing}
%The MWA
\subsection{The MWA}
The MWA is an interferometric array of phased array tiles operating in the 80-300\,MHz radio band. Each tile consists of a 4x4 grid of bow-tie shaped dipoles that are used to form a beam on the sky with a full width of 26\arcdeg$\lambda$ at the half power point. Signals from individual antennas are summed by an analog, delay-line, beamformer which can steer the beam in steps of 6.8\arcdeg$cos(l)$.  The signal is digitized over the entire bandwidth but only 30\,MHz are available at any one time.  This 30\,MHz of bandwidth is broken into 1.28\,MHz ``coarse'' bands by a polyphase filter-bank in the field and sent to the correlator \citep{Ord:2015PASA...32....6O} where it is further channelized to 40kHz, cross-multiplied and then averaged at 0.5 second intervals.  More details on the design and operation of the MWA can be found in \cite{Lonsdale:2009p7913} and \cite{Tingay:2013p9022}.

%TODO maybe move this elsewhere.
%The spectral shape of the coarse polyphase filter is known somewhat imperfectly and is thought to include a small amount of aliasing from adjacent coarse channels, though the exact amount is currently under investigation. This spectral response is corrected to first order during the first post-correlator step, and to second order by the calibration step.
%The EoR program
\subsection{The 21\,cm Observing Program}
The MWA reionization observing scheme spans two 30\,MHz tunings, 140-170\,MHz (9.2$<z<$7.5) and 167-196\,MHz (7.5$<z<$6.25) and two primary minimal foreground regions (RA 0h and 4h, Dec -27\arcdeg); both transit the zenith at the MWA's  latitude and are near the galactic pole. A third pointing towards Hydra A is also observed; see Figure \ref{fig:fields} for an overview. Here we focus on the low redshift tuning, and the RA=0h pointing, where the band is chosen for its lower sky temperature and pointing is chosen for its ease of calibration --having fewer bright, resolved sources; see Table \ref{tab:observing} for a listing of observing parameters.


\begin{figure*}[htbp]
\begin{center}
\includegraphics[width=\textwidth]{figures/EoR_FoV.png}
\caption{An overview of the MWA reionization observation strategy. The background image is a cartesian view of the sky at radio wavelengths and the circles indicate the deep fields observed by the MWA EoR project.  Here we are focusing on field 0, centered on Dec -27\arcdeg and RA 0h. Inset is a foreground subtracted image of the field made using the Real Time System (described more completely in \ref{sec:RTS}. A model of smooth (galactic and unresolved) emission has not been subtracted and dominates the residual map of this 22\arcdeg wide image. Not visible in this average map is variation from channel to channel caused by sources far beyond the field of view which shows up as the wedge in 2d power spectra.}
\label{fig:fields}
\end{center}
\end{figure*}

%The data included here
\subsection{Data Included Here}
During observing, the beam-former was set such that the target region repeatedly drifted through the field of view.  With an available beamformer step size of 6.8\arcdeg; each drift was about 30 minutes long.  This was done for a total of 6 pointings in a night, or about 3 hours. The data included here include the two pointings leading up to the target crossing zenith, the zenith pointing, and then three more pointings after the transit crossing.  Data were recorded in 112 second units for a total of 96 snapshots. These snapshots are the basic unit of time on which many operations become independent -eg RFI flagging, FHD calibration and imaging.\footnote{Note that this is not true in the RTS which uses a time interval scaled by the baseline length.}   Each snapshot is flagged for interference using the AOFlagger \citep{offringa:2010rfim.workE..36O}\footnote{ \url{sourceforge.net/projects/aoflagger} } algorithm and then averaged to 2 seconds and 80kHz.  As described in \cite{2015PASA...32....8O}, the interference environment at the Murchison Radio-astronomy Observatory is benign and generally requires flagging of about 1\% of the data.   Though the full set of linear polarization parameters are correlated, and Stokes I images and power spectra are the final product of interest, at this stage of the analysis the instrumental polarizations have been found to be more instructive; with one exception, only the linear X (east-west) polarization is examined here.   The same set of snapshots is used in every pipeline run.


\begin{deluxetable*}{lcr}
\tablecolumns{2}
\tablecaption{MWA EoR Observing Parameters }
\tablehead{
\colhead{parameter}  & 
\colhead{value} 
}
\startdata
field of view & 26\arcdeg$\lambda$ FWHM \tabularnewline
tuning & 166-196\,MHz  redshift range $7.56<z<6.25$ \tabularnewline
target area & (RA,Dec) 0h00m, -27\arcdeg00m \tabularnewline
primary beam pointing grid & 6.8\arcdeg \tabularnewline
snapshot length & 112 seconds\tabularnewline
time and frequency resolution & 0.5\,s, 40 kHz  \tabularnewline
post-flagging resolution & 2s, 80\,kHz \tabularnewline
time & 3 hours on August 23, 2013, six 30 minute pointings or 96 snapshots\tablenotemark{a} 
\tabularnewline
\enddata
\tablenotetext{a}{The same data set is used in every pipeline run}
\label{tab:observing}
\end{deluxetable*}





\section{Power Spectrum Pipelines}
\label{sec:pipelines}
In this section we review the basic analysis components, introduce the basic pipeline components, define some terms common to all, and then in sections \ref{sec:RTS}-\ref{sec:CHIPS} give finer grain descriptions of the specific implementations.

%about the power spectrum
The 21\,cm brightness at high redshift is weak and detectable by first generation instruments only in	 statistical measures such as the power spectrum. The spectral line signal is a three dimensional probe, two spatial dimensions and a third from the mapping of the spectral axis to line-of-sight distance via the Hubble relation. 3D power spectra are computed at multiple redshift slices through the observed band and then, taking advantage of statistical rotational symmetry, averaged in shells of constant wavenumber $k$.  The power spectrum is well matched to an interferometer, which natively measures spatial correlation; the baseline vector maps to the perpendicular wavemode $k_\perp$.  An additional Fourier transform in the spectral dimension provides $k_\parallel$.  

%about foregrounds
The principle challenge to detecting 21\,cm at very high redshifts is foreground emission. At frequencies below 200\,MHz the principle sources are synchrotron emissions from the local and extragalactic sources. Synchrotron is generally characterized by a smooth spectrum which rises as a power law towards lower frequencies. The local Galactic neighborhood has a significant amount of spatially smooth power appearing at short $k_\perp$ modes, extragalactic point sources appear equally on all scales and dominate over the Galaxy on long $k_\perp$ modes.

%about foreground subtraction
An analysis pipeline has two main components: one which removes foregrounds --leaving as small a residual as possible-- and a second which computes an estimate of the power spectrum.   Foreground subtraction is generally the domain of calibration and imaging software where the focus is on building an accurate forward model of the telescope and foregrounds.  Challenges include: ionospheric distortion, a very wide field of view, primary beam uncertainty, polarization leakage, and catalog inaccuracy. Though a number of calibration and imaging software packages --such as CASA and Miriad-- are available, these challenges have necessitated the creation of custom software.  As an added benefit, having developmental control of the imager enables the export of the instrument model in the form of weights and variance cubes which are necessary for the calculation of power spectrum error bars as described below. 

As we mentioned in the introduction, a horizon-to-horizon model of the sky must be subtracted at high precision from each two minute snapshot across thousands of hours of data. At this scale, deconvolution and self-calibration of each snapshot image is not computationally tractable.  In both FHD and RTS the sky model is left static and instead the focus is on refining the instrument model used in forward modeling and averaging of calibration solutions.  This instrument model also provides information on the instrumental covariance.


%about power spectrum estimation and why we need an instrument model
Detailed knowledge of instrumental covariance is essential to overcoming the two main challenges in estimating the power spectrum: 1) minimizing the effects of residual foregrounds and 2) faithfully recovering the underlying 21\,cm power.   As discussed in the introduction, simulations and early observations have shown that foregrounds tend to ``contaminate'' only specific $k$ modes, using a model of instrumental covariance the power can be isolated to fewer modes.  Accurate recovery of the 21\,cm background will, to first order, depend on the ability to correctly calculate error bars.  Initial power spectra are expected be of low signal to noise, an accurate estimate of error is essential to estimating the significance of any putative detection \citep{Pober:2014p10390,Beardsley:2013p9952}. 

%about the pipelines.
Pipeline development has centered around the construction of two main end-to-end analysis tracks shown in Figure \ref{fig:pipes} and described in more detail in \chipscite{} and \eppsiloncite{}. A third pipeline described in \dilloncite{} substitutes an alternate power spectrum calculation method in place of \eppsilon{}. The primary difference between these pipelines is the division of responsibilities between foreground subtraction and power spectrum calculation. Some power spectrum methods take as input spectral image cubes output by the calibration and foreground subtraction system.  The imager also provides a model of the telescope window function (variance) in the form of a cube of weights (weights squared) formed by gridding down `1's in the same way as the data. These encode the full covariance of the telescope's window function.  Each set of cubes is generated with both even and odd sample cadences; the cross multiplication provides a power spectrum free of noise bias and the difference an estimate of noise.

Methods which take time-ordered data as input generate their own instrument model internally.  The pipeline submodules names and citations are listed in Table \ref{tab:pipeline_cites} and described individually in sections \ref{sec:RTS} - \ref{sec:empirical_cov}.  

\begin{deluxetable*}{llr}
\tabletypesize{\footnotesize}
\tablecolumns{2}
\tablecaption{MWA EoR Pipeline components }
\tablehead{
\colhead{Short Name} &
\colhead{Name}  & 
\colhead{Citations} 
}
\startdata
Cotter & AOFlagger + Averaging & \cite{offringa:2010rfim.workE..36O} \tabularnewline
RTS & Real Time System&\cite{Mitchell:2008p707,Ord:2010p8442} \tabularnewline
FHD & Fast Holographic Deconvolution &\cite{Sullivan:2012p9457}\tablenotemark{1}  \tabularnewline
\eppsilon{} & Error Propagated Power Spectrum with InterLeaved Observed Noise & \eppsiloncite{}\tablenotemark{2} \tabularnewline
CHIPS & Cosmological HI Power Spectrum& \chipscite{}  \tabularnewline
\empirical{} & Empirical Covariance Estimator & \dilloncite{}


\enddata
\tablenotetext{1}{\url{github.com/miguelfmorales/FHD}}
\tablenotetext{2}{\url{github.com/miguelfmorales/eppsilon}}
\label{tab:pipeline_cites}
\end{deluxetable*}



% End-to-end pipes FHD-\eppsilon
%One pipeline uses Fast Holographic Deconvolution (FHD\footnote{\url{github.com/miguelfmorales/FHD}}) for calibration and foreground subtraction, followed by either \eppsilon\footnote{\eppsilon:Error Propagated Power Spectrum with InterLeaved Observed Noise; \url{https://github.com/miguelfmorales/eppsilon}} or \empirical{} \dilloncite{} to estimate the power spectrum. 
%
%The independent  pipeline uses an offline version of the MWA Real Time System (RTS) followed by CHIPS\footnote{Cosmological HI Power Spectrum} to estimate the power spectrum.  FHD is described in detail by \cite{Sullivan:2012p9457} and the RTS by \cite{Ord:2010p8442}. \eppsilon{}, CHIPS and \empirical{}, as applied to the data published here, are described in \eppsiloncite{}, \chipscite{}, and \dilloncite{}, respectively.

%TODO  move more common elements into this section 
% TODO mention major and minor connections between pipeline elements here at the top


   
   
%   Models (cites) and arguments from isotropy and homogeneity suggest that over redshift ranges less than 0.5, 21\,cm emission is statistically rotationally symmetric; the 1D power spectrum, averaged in shells of constant wavenumber ($k$), preserves cosmological signal. 
  
    
%  The MWA collaboration has developed two independent pipelines which take in raw, time-ordered data and output a power spectrum.  Key steps include calibration to a sky model, subtraction of bright foregrounds, generation of image cubes,  transformation into 3D Fourier space, and estimation of the 1D spherically averaged power spectrum.
%  
%  calibration and imaging modules which subtract the foregrounds and two power spectrum estimators. All are developed independently, sharing very little code, yet are interconnectable via common data formats to give four possible pipeline paths.These two paths and their interactions are sketched out in Figure \ref{fig:pipes}.


%The imaging and foreground subtraction portion of the pipeline can be handled by either of two custom packages.  The MWA Real Time System (RTS; \cite{Ord:2010p8442}) was initially designed to make images in real time from the MWA 512.  On the de-scoped 128 element array, it has been implemented as an offline system, where it has been adjusted to compensate for the lower filling factor.  Fast Holographic Deconvolution (FHD; \cite{Sullivan:2012p9457}) is a custom interferometric imaging package developed for interferometric instruments with a focus on accounting for very wide field of view antenna responses found on phased arrays of dipoles.  Both systems were developed in parallel with the construction and commissioning of the MWA to provide a detailed introspection on unique aspects of this experimental telescope. Each can calibrate a data set against a model, subtract a model, deconvolve images and use precision models of the instrument informed by the commissioning process including effects such as tile to tile primary beam variation and 0.1dB cable reflections.  Foreground inputs include catalogs, images of extended emission and wavelet models of bright, mostly compact, sources.  In addition, each has its own unique feature set developed as part of the experimental process.

\begin{figure*}[htbp]
\begin{center}
\includegraphics[width=\textwidth]{figures/MWA_Pipes.png}
\caption{Parallel pipelines with cross-connections after foreground subtraction and imaging are compared against each other. Pipelines used to reach the cited power spectrum results are indicated with thin lines; citations for each block are listed in Table \ref{tab:pipeline_cites}. Cotter uses AOFlagger to flag RFI and averages by a factor of 8. The averaged data are passed to either FHD or RTS for calibration, foreground subtraction and imaging. Both of these packages generate integrated residual spectral image cubes as well as matching cubes of weights and variances.  \eppsilon{} and \empirical{} use these cubes to estimate the power spectrum. Meanwhile, CHIPS taps into the RTS and FHD data stream to get calibrated and foreground-subtracted time-ordered  visibilities which it then grids with its own instrument model to estimate the power spectrum. 
%imager produces an image, instrument model (weights and variances)
}
\label{fig:pipes}
\end{center}
\end{figure*}

\subsection{Calibration and Imager \#1: RTS}
\label{sec:RTS}

The MWA Real Time System (RTS; \cite{Mitchell:2008p707,Ord:2010p8442}) was initially designed to make wide-field images in real time from the MWA 512-tile system \citep{Mitchell:2008p707}.  On the de-scoped 128 element array, it has been implemented as an offline system, where it has been adjusted to compensate for the lower filling factor \citep{Ord:2010p8442}.  The RTS incorporates algorithms intended to address a number of known challenges inherent to processing MWA data, including; wide-field imaging effects, direction-dependent (DD) antenna gains and polarization response, and ionospheric refraction of low-frequency radio waves. Each MWA observation (112s) is processed through a separate instance of the RTS. The RTS is also parallelized over frequency so that each coarse channel (1.28\,MHz broken into 40 kHz channels) is processed largely independently of the other coarse channels, with only information about the measured ionospheric offsets communicated between processing nodes.  Calibration and model subtraction were based on the Molonglo Reference Catalog \citep{Large:1981p7798}. 

The RTS calibration strategy is based upon the `peeling' technique proposed by \cite{Noordam:2004p2379} and a foreground model using a cross-matching of heritage southern sky catalogs\footnote{See Table \ref{tab:cal_sub_parms}} with the MWA Commissioning Survey. The brightest apparent calibrators in the field of view are sequentially and iteratively processed through a Calibrator Measurement Loop (CML). During each pass through the CML; i) the expected (model) visibilities of known catalogue sources are subtracted from the observed visibilities. For the data processed in this work, $\sim$1000 sources are subtracted for each observation. ii) The model visibilites for the targeted source are added back in and phased to the catalog source location. Any ionospheric offset of the source can now be measured by fitting a phase ramp to the phased visibilities. iii) The strongest sources are now used to update the direction-dependent antenna gain terms, while weaker sources are only corrected for ionospheric offsets. For this work, 5 sources are used as full DD calibrators and 1000 sources are set as ionospheric calibrators. The CML is repeated until the gain and ionospheric fits converge to stable values. A single bandpass for each tile is found by fitting a 2nd order polynomial to each coarse channel. The $\sim$1000 strongest sources are then subtracted from the calibrated visibilities.   Calibration and model subtraction parameters are summarized in Table \ref{tab:cal_sub_parms}.  Model subtracted visibilities are passed to the RTS imager and to the CHIPS power spectrum estimator. %how much flux is subtracted in total?

The RTS imager uses a snapshot imaging approach to correct for wide-field and direction-dependant polarization effects. Following calibration, the residual visibilities are first gridded to form instrumental polarization images which are co-planar with the array. These images are then regridded into the HEALPIX \citep{Gorski:2005p7667} frame with wide-field corrections.  Weighted instrument polarisation images are stored, along with weight images containing the Mueller matrix terms, so that further integration can be done outside of the RTS. It is also possible to use the fitted ionospheric calibrator offsets to apply a correction for ionospheric effects across the field during the regridding step or subtraction of catalog sources, but in this work this correction has not been applied. These snapshot data and weight cubes are then integrated in time to produce a single healpix cube. This cube, averaged over the spectrum, is shown, with and without foregrounds, in Figure \ref{fig:image_compare}.


\begin{deluxetable}{lll}
\tablecolumns{3}
\tabletypesize{\footnotesize}
\tablewidth{0pt} 
\tablecaption{MWA Reionization Calibration and Model subtraction Parameters }
\tablehead{
\colhead{correction}  & 
\colhead{RTS} &
\colhead{FHD} 
}
\startdata
global passband & NA & 768 channels  \\
per antenna passband & 48 per tile\tablenotemark{a} & 3 per tile\tablenotemark{b}\\
per antenna gain & 2\tablenotemark{c} & 2\tablenotemark{c}  \\
peeling parameters & 4\tablenotemark{d} & None \\
peeled sources & 5 & None\\
subtraction catalog & Line\tablenotemark{e} & Carroll\tablenotemark{f} \\
number subtracted & 1000 & 1000 \\
\bf{Total free parameters} & \bf{6,420} & \bf{1,408} \\
\enddata
\tablenotetext{a}{2nd order poly per coarse channel}
\tablenotetext{b}{poly fit over full band, 2nd order for amp, 1st for phase}
\tablenotetext{c}{amplitude and phase}
\tablenotetext{d}{Direction Dependent (DD) gain fits}
\tablenotetext{e}{MWA Commissioning Survey\cite{Hurley-walker:2014p45},\cite[VLSSr]{2014MNRAS.440..327L},\cite[MRC]{Large:1991p7760},\cite[SUMSS]{Mauch:2003p8804},\cite[NVSS]{Condon:1998p7986},cross matched using PUMA (Line et al, in prep) \url{https://github.com/JLBLine/PUMA}}
\tablenotetext{f}{Sources deconvolved from snapshots with FHD, (Carroll et al in prep)}
\label{tab:cal_sub_parms}
\end{deluxetable}



\subsection{Calibration and Imager \#2: FHD}
\label{sec:FHD}
Fast Holographic Deconvolution (FHD, \cite{Sullivan:2012p9457}) is a calibration and imaging algorithm designed for very wide field of view interferometers with direction- and antenna-dependent beam patterns using the tile beam pattern to grid visibilities to the $uv$ plane, and its Hermitian conjugate for de-gridding simulations to form model visibilities. 

The FHD calibration pipeline generates a model data set, computes a calibration solution which minimizes the difference with the data, smooth the calibration solution to minimize the number of free parameters, and then outputs the residual. The calibration model is formed from sources found by deconvolving, in broadband images, hundreds of snapshots and retaining those which are common to all snapshots and pass other consistency checks (Carroll et. al. in prep). In each snapshot sources are included in the model if they are at or above 1\% of the peak primary beam, this amounts to about 1000 sources and a flux limit of about 1Jy (it varies slightly snapshot to snapshot). %TODO: check this flux cut.

 Per-antenna and per-channel complex gain solutions are then computed using the Alternating Direction Implicit technique described in \citet{sal14}.  This generates a gain and phase for every channel on every tile, for each 112s snapshot.  These solutions are then averaged over all tiles to form a single passband, which corrects for the majority of the spectral dependent effects such as the response of the coarse channel passband and cable attenuation.  This single passband solution is divided out of each per tile solution and each residual fit for a 2nd order amplitude polynomial and a first order phase polynomial. This process happens iteratively, with convergence measured by comparing the relative difference between residual visibilities. 10 iterations to converge to a stable residual was the norm.  The residual time-ordered visibilites are then passed to CHIPS and to FHD imaging for formation of spectral cubes.  The FHD imager  produces snapshot cubes using the MWA beam model described by \cite{Sutinjo:2015RaSc...50...52S} and averaged in time. This image, further averaged over the spectrum, is shown, with and without foregrounds, in Figure \ref{fig:image_compare}.

\subsection{Comparing Calibration and Imaging Steps}
\label{sec:comparing_imaging}
Through the parallel-but-convergant development of these imagers have emerged two very similar systems, however some differences remain in the analysis captured here. The two primary differences are in the treatment of calibration and in the subtracted catalogs.  

In both pipelines the calibration is a two step process. First, calibration solutions for each channel, and antenna are computed by solving for the least-squares difference with a model data set. Next, those solutions are fit to a model of the array; for example fitting a polynomial to the bandpass. FHD and RTS take different approaches to this step, a fact reflected in the the number of free parameters in this fit. A smaller number of parameters minimizes the possibility of cosmological signal loss; more free parameters can absorb physics missing from the instrument model.  As tabulated in Table \ref{tab:cal_sub_parms} the RTS fits for 6,420 free parameters while FHD fits for 1,408.  In practice this is a lower limit as it does not count any antennas which might be flagged during the calibration process. 

The primary difference is in the treatment of the passband.  There are a number effects which show up in the passband calibration. The edges of the 1.28\,MHz bands are known to be subject to aliasing from adjacent coarse channels and so are flagged creating a regular sampling function which shows up as the characteristic horizontal lines in the 2D power spectrum. Added to this is a small amount of interference flagging.  Additionally, reflections at analog cable junctions show up as additional spectral ripple corresponding to the length of the cables.    

The RTS fits for a low order polynomial on every 1.28\,MHz chunk on every antenna, while FHD averages each channel over all antennas to get a common passband for all and then fits a low order polynomial to get any tile to tile variation. This significantly reduces the number of free parameters and the likelihood of signal loss, though leaving open the possibility of additional un-modeled instrumental effects.

%TODO add 
The construction of the foreground subtraction model is also a point of difference between the two pipelines.
As noted in Table \ref{tab:cal_sub_parms}, the both foreground models contain 1000 sources however the two sets are derived by different means. The RTS catalog cross-matches multiple heritage southern sky catalogs with the MWA Commissioning Survey using the Bayesian cross-matcher PUMA (Line et al in Prep).  The FHD subtraction model contains sources found in a deep deconvolution of this same data set. Both catalogs have the goal of producing a reliability set of sources that minimizes false positives and accurately reflects resolved components, though they go about it in different ways. The FHD catalog focuses on the reliability aspect by performing a deconvolution on every snapshot used in the observation and selecting sources which appear in most observations (Carroll et al, in prep). The RTS catalog has used the somewhat less precise MWA commissioning but by cross-matching these sources against many other catalogs of known sources and fitting improved positions and fluxes, the accuracy is seen to increase.


\begin{figure*}[htb]
\begin{center}
\includegraphics[width=1\textwidth]{figures/FHD_RTS_image_compare.png}
%\includegraphics[width=1\textwidth]{figures/FHD_2014c_RTS_March_2015_polswitch.png}
%\includegraphics[width=1\textwidth]{figures/FHD_2014c_RTSnominal_polswitch.png}
%\includegraphics[width=1\textwidth]{figures/FHD_2014c_RTS_Aug_res.png}
\caption{A comparison between the image outputs of the FHD (left), RTS (center) and their difference (right) averaged in the spectral dimension and projected from native healpix to flat sky.  In the top row, no foreground model has been subtracted, on the bottom both have subtracted 1000 sources.  The images have been left in the natural weighting used by image-based power spectrum schemes and no deconvolution has been applied. The difference between foreground subtracted images reveals a good agreement on large scale structure and small differences in the fluxes of a few sources.
%TODO this caption could be improved
\label{fig:image_compare}}
\end{center}
\end{figure*}


\subsection{Power Spectrum \#1: \eppsilon}
\label{sec:EPPSILON}
\eppsilon{} calculates a power spectrum estimate from image cubes and
directly propagates error bars through the full analysis, see \eppsiloncite{} for a full description. The design criteria for this method is to make a relatively quick and uncomplicated estimate of the power spectrum to provide a quick turnaround diagnostic. The input to \eppsilon{} is gridded image cubes for  each 112s snapshot, such as are produced by FHD or RTS imaging, in which the data has been split into interleaved time samples (referred to as even and odd cubes) along with matched cubes containing the modeled instrumental weighting and variance. These snapshot healpix cubes are integrated in time keeping pixels with a beam weight of 1\% or more, a cut which effectively limits the field of view to $\sim$20\arcdeg. The accumulated data, weight and variance cubes are Fourier transformed in two dimensions to take them to $uvf$ space where the spatial covariance matrix is assumed to be diagonal. This is a better assumption if the $uv$ pixel size is well matched to the primary beam size so we restrict the spacing of modes in the spatial DFT to be equal to the inverse of the primary beam field of view. The data (variance) cubes are then divided by the weight cubes (weight cubes squared) to arrive at the best estimates of the sky and variances. Next the sum and difference of the even and odd cubes are computed with variances given by adding the reciprocal of the even and odd variances in quadrature. The difference cube then contains only noise (as long as the time interleaving is fine enough) and the sum cube contains both sky signal and noise.

The next step is to Fourier transform in the frequency direction. Here we choose to use the full 30\,MHz spectral window, weighted by a Blackman-Harris window function, which heavily down-weights the outer half of the band to effectively sample 15\,MHz; a cosmological redshift range of 0.86. This weighting scheme minimizes the covariance of bright foreground modes between power spectrum modes as described in \cite{Thyagarajan:2013p10039,Parsons:2012p8896,Vedantham:2012p9026}, among others.  The spectral Fourier transform uses the Lomb \& Scargle periodogram to minimize the effects of regular gaps in the spectrum which occur every 1.28\,MHz.    The sky signal power is  estimated by the square of the sum cube minus the square of the difference cube, which  is mathematically identical to the even/odd cross power if the even and odd variances are identical, while the square of the difference cube provides a realization of the noise power spectrum. Diagnostic power spectra in which the wedge is visible are generated by averaging cylindrically to a two dimensional $k_{\|},k_{\bot}$ power spectrum.  These are shown in the left column of Figure \ref{fig:pspec_compare}.  One dimensional power spectra (shown in Figure \ref{fig:1D_pspecs}), are calculated by averaging along shells of constant $k$, masking points within the wedge and weighting by variance\footnote{Here defined, conservatively, as the light travel time across the baseline plus the delay associated with the pointing furthest from zenith}.

%TODO 1D power spectra?





\subsection{Power Spectrum \#2: CHIPS}
\label{sec:CHIPS}
The CHIPS power spectrum estimation method computes the maximum likelihood estimate of the 21~cm power spectrum using an optimal estimator formalism and is more completely described in \chipscite{}.  The design criteria for this method were to fully account for instrumental and foreground induced covariance in the estimation of the power spectrum.  The approach is similar to that used by \cite{Liu:2011p8763}, but with the key difference of being performed entirely in $uv$-space, where the data covariance matrix is simpler (block diagonal), and feasible to invert. This approach also allows straightforward estimation of the variances and covariances between sky modes by direct propagation of errors. CHIPS takes as input calibrated and foreground subtracted time-ordered visibilities. Tapping into the pipeline post-calibration but before imaging, CHIPS uses its own internal instrument model to estimate and propagate uncertainty.	

The method involves four major steps: (1) Grid and weight time-ordered visibility channels onto a $uvw$-cube using the primary beam model, (2) compute the least squares spectral (LSS) transform along the frequency dimension to obtain the best estimate of the line-of-sight spatial sky modes (this technique is comparable to that used by \eppsilon), (3) compute the maximum-likelihood estimate of the power spectrum, incorporating foregrounds and radiometric noise,  averaging $k_x$ and $k_y$ modes into annular modes on the sky, $k_\bot$; (4) compute the uncertainties and covariances between power estimates. The first step is the most computationally-intensive, requiring processing of all the measured data. The principle departure point for CHIPS from \eppsilon{} is in the much finer resolution of the $uv$ grid.  Using an instrument model, CHIPS calculates the covariance between $uv$ samples as a function of frequency.  Since the beam and $uv$ sampling function are both highly chromatic, extra precision in this inversion is thought to be highly beneficial. After a line of sight transform similar to that used by \eppsilon{}, this covariance information is inverted to find the Fisher Information, the maximum likelihood power spectrum, and covariances between measurements.  The maximum likelihood estimate of the power in each $k_\bot,k_\parallel$ mode is shown in the right column of Figure \ref{fig:pspec_compare} and averaged in spherical bins in Figure \ref{fig:1D_pspecs}. This last averaging step includes an additional weighting by the known power spectrum of a confused foreground in a process described in more detail for these data by \chipscite{}. The power spectra have been split into three redshift ranges of $\Delta z\sim$0.5. Though well above the predicted cosmological signal level, the measurements are notably consistent with noise across a wide range of $k$. 

\subsection{Power Spectrum \#3: Empirical Covariance}
\label{sec:empirical_cov}

The \empirical{} power-spectrum estimation method computes a 1D power spectrum using a quadratic estimator formalism. The method and its application to this data is described in more detail by \dilloncite{}; here we provide a short description.

The quadratic estimator method of \cite{Liu:2011p8763} treats foreground residuals in maps as a form of correlated noise and simultaneously downweights both noisy and foreground-dominated modes, keeping track of the extra variance they introduce into power spectrum estimates. This technique can be computationally demanding but using acceleration techniques described by \cite{Dillon:2013p10497}, has been applied to the previous MWA 32T results of \cite{Dillon:2014p9788} while a very similar technique, working on visibilities rather than maps, was used for the recent PAPER 64 results of \cite{2015ApJ...809...61A}.  \dilloncite{} build on these methods to mitigate errors introduced by imperfect mapmaking and instrument modeling through empirical covariance estimation, assuming all data covariance is sourced by foregrounds.

\empirical{} takes as input FHD calibrated images with foregrounds subtracted as well as possible, split into even and odd time-slices and averaged over many observations. From these cubes, it estimates the frequency-frequency foreground residual covariance in annuli in $uvf$ space, assuming that different uv cells have uncorrelated foreground residuals. This assumption, similar to that made by CHIPS, allows the combined foreground and noise covariance to be inverted directly. The resulting power spectrum is shown in Figure \ref{fig:1D_pspecs} for direct comparison with the CHIPS result. 



\subsection{Benefits of Comparison}
\label{sec:benefits_of_comparison}


One benefit from having multiple pipelines is the freedom to investigate  different optimization axes.  The design of the \eppsilon{} power spectrum estimator emphasizes speed and relative simplicity, choices  motivated by the need to understand the effect, on the power spectrum, of processing decisions such as observation protocol, flagging, and calibration. Using \eppsilon{} we have discovered and corrected multiple systematic effects. Primarily those of a spectral nature which were not obvious in imaging but quite apparent in the 2D power spectrum. With the ability to quickly form power spectra on different sets of data, \eppsilon{} has been an important tool for selecting sets of high quality data. 

In contrast, CHIPS starts from time-ordered data and in its calculations emphasizes a more full accounting of instrumental and residual foreground covariance. Not only does this higher resolution covariance calculation provide a more accurate accounting of the instrumental window function on the power spectrum, but it also allows for more precise weighting schemes based on knowledge of the statistical properties of the residual foregrounds. This is useful when making 1D power spectra where foreground-like modes can be down-weighted in the average. 


\section{Comparison Discussion}
\label{sec:results}
%TODO XXX put FHD and RTS, and W/ Foregrounds and subtracted on the figure
Inspecting a comparison of the images and power spectra reveals several common features. Images before and after foreground subtraction are shown in Figure \ref{fig:image_compare}, presented in the natural weighting used by the power spectrum estimators without application of any deconvolution.  Putting the same 3 hours of MWA data\footnote{NB: To simplify data handoff for the RTS to \eppsilon{} step only the 30 minute zenith integration was used for that pathway.} into each pipeline, we inspect output images before and after foreground subtraction. The pre foreground-subtracted (sometimes called the ``dirty'' image) have the largest difference with slight differences in point spread function leading to high residuals around bright sources. These are well modeled in the subtraction step but without deconvolution subtract poorly in the image plane.  The foreground subtracted images (sometimes called ``residual'' images) show a much closer agreement both around the subtracted sources and in the large scale structure. Large scale structure is more difficult to distinguish . Inspection of the snapshot images before averaging in time and frequency revealed that the structure is constant across both time and frequency, which suggests real galactic emission rather than sidelobes or aliasing.  

% TODO XXX
%what else to say about the image comparison? maybe some basic stats about the fluxes and fractional error.


%The effectiveness of foreground subtraction is highly dependent on the choice of sources included in the model: too few sources subtracted leaves an excess of power which must be removed as extra free parameters in the covariance step, too many sources leaves open the possibility of mis-subtraction as the number of sources and amount of sky covered increases. In the middle row we have locked both pipelines to the RTS's smaller but more readily diagnostic catalog of 300 sources.  This subtraction step decreases the image rms by half and results in a somewhat flatter difference image.  In the bottom row we have allowed each system to select from its internal catalog based on nominal operating parameters, for the FHD this means the number of sources increases to 1000 and results in a further decrease in image rms by \~33\% and a smaller 20\% decrease in the \emph{difference} with the RTS image.   This is the residual data set which is passed to the power spectrum estimation portions of the pipelines.

 %  The primary way in which the images in Figure \ref{fig:image_compare} differ is that both consistently present a significant amount of large scale power which, while visually similar in some respects, differs at the 50 to 100\% level.  The power is generically described as several large ``islands'' of power (both positive and negative) and which, in the difference image, give the appearance of beginning to dissipate as more sources are subtracted.  
%\begin{figure}[htbp]
%\begin{center}
%\includegraphics[width=\columnwidth]{figures/MWA128_radial_uv_density.png}
%\caption{\label{fig:density_plot} The radial density of samples in the uv plane is dominated by short spacings but the calibration model is most accurate on the longer spacings.  The MWA is optimized to be sensitive to degree-scale epoch of reionization structure, as we see from the cumulative fraction of weights (black, right hand scale), some 50\% of the baselines are shorter than 120 wavelengths and a large fraction (black, left hand scale) are inside of 50 wavelengths.  At the same time, power from Galactic foregrounds is known to dominate on these short spacings. Until a model of Galactic emission, of sufficient precision for calibration purposes, is available, baselines below $\sim$40 wavelengths are excluded from the calibration operation.  Though data from these baselines are still included in the imaging and power spectra presented here, the large-scale results stand to improve significantly from from adoption of diffuse emission models into the calibration. }
%\label{default}
%\end{center}
%\end{figure}


%The residual, after subtraction of many hundreds of sources, tells a fairly consistent story of a significant amount of large scale power remaining, though the two imagers disagree somewhat on the exact arrangement.  The primary question is whether any large-scale structure is ``real'', rather than some mis-calibration or other artifact that affects the large number of short baselines. Calibration errors in a traditional interferometer having uniformly distributed baselines reveal themselves as side lobes around bright point sources; similar errors on the core-heavy MWA reveal themselves as artifactual large-scale power which is more difficult to distinguish from true emission.
%
%One possible origin of disagreement follows from a consideration of the physical layout of the MWA and the  approach to calibration used in both imagers. The MWA is optimized to be sensitive to degree-scale epoch of reionization structure \citep{Beardsley:2013p9952}; reconstruction of the large scales is crucial to subtracting modeled foregrounds at small $k$, where reionization is brightest.    As we see from radial distribution of $uv$ weights in Figure \ref{fig:density_plot},  50\% of the baselines are shorter than 120 wavelengths (0.5\arcdeg scales) and a large fraction are highly localizes inside of 50 wavelengths (1.1\arcdeg scales).  At the same time, power from Galactic foregrounds is known to dominate on these scales. Until a model of Galactic emission, of sufficient precision for calibration purposes, is available, baselines below $\sim$40 wavelengths have been excluded from the calibration process, though data from these baselines are still included in the imaging and power spectra presented here, the large-scale results stand to improve significantly from from adoption of diffuse emission models into the calibration.


\subsection{Power Spectra}

Application of our two independent power spectrum estimators to our two calibration and foreground subtraction pipes gives us a total of four different power spectra (Figures \ref{fig:pspec_compare} and \ref{fig:1d_kperp}).  Each power spectrum estimator has been developed to target the output from a ``primary'' calibration and foreground subtraction process --the diagonal elements of Figure \ref{fig:pspec_compare}-- and have been highly optimized to that up-stream source of data.  The off-diagonal power spectra were created using auxiliary links which import the data and the metadata produced by the foreground subtraction step.  Since they are less highly optimized, lacking as they do the advantage of a close working relationship, these pathways represent an upper limit on the variance to be expected from small analysis differences but allow us to look for effects common to foreground subtraction or to power spectrum method.


Properties shared by all are the large amount of power at low $k_{\parallel}$ roughly at an amplitude of $10^{15}$ mK$^2$/Mpc$^3$ and approximately flat in $k_{\perp}$ and a steep rise in power at low $k_\perp$. The amplitude agreement is particularly apparent in Figure \ref{fig:1d_kperp}. A model of smooth galactic emission has not been subtracted which likely contributes to this steep rise. The ``wedge'' shaped linear dependance on baseline length in the 2D power spectra is due to the inherently chromatic response of a wide field instrument to smooth spectrum foregrounds; sources entering far from the phase center appear as bright pixels at higher $k_\parallel$ with sources on the horizon at the edge indicated by Figure \ref{fig:pspec_compare}'s  solid black line. The solid and dotted lines in the figure indicate the upper boundaries of power from sources at the horizon and at the beam half power point, respectively.  With the exception of some instrumental features foreground power is well isolated within this expected boundary. This emission is also visible in the image cubes as side-lobes extending from outside of the imaged area which move as function of frequency.  Observations recorded when the Galactic plane is near the horizon have a much larger wedge component and have been excluded from this analysis. See \cite{2015ApJ...804...14T} and \cite{2015ApJ...807L..28T} for a detailed discussion of the foreground contributions to the power spectra in this data. 
%TODO fix Nithya's cite
The two main instrumental systematics are horizontal striping due to missing or poorly calibrated data at the edges of regular coarse passbands and vertical striping due to spectral variation near uneven $uvf$ sampling. The former can be minimized by careful calibration of the passband, the latter by $uv$ rotation synthesis and by accounting for covariance between $uvf$ samples. 

The most noticeable difference between the different pipeline paths is in the noise level of the so-called ``window'' above the horizon and below the first coarse passband line (between 0.1 and 0.3 $k_\parallel$ and 0.01 and 0.05 $k_\perp$). FHD to \eppsilon{} is the only path to have a noise-like window in the 2D space, with a number of points dipping below zero. Similarly, both RTS power spectra have a few areas without positive bias, though only at much higher $k$s.  One commonality between all power spectra with positive bias is the amplitude of the coarse passband lines.
%The most noticeable difference between foreground removal methods is in the shape of the power spectrum at $k_\parallel=0$.  Where power spectra using data from FHD have a fairly uniform increase in power with decreasing $k_\perp$ those using RTS data have a roughly flat spectrum which increases dramatically in the few bins below $k_\perp<.002$ or below 20 wavelengths.  We note from Figure \ref{fig:density_plot}) that the number of baselines drops precipitously below 20 wavelengths and draw the preliminary conclusion there must be some difference in how RTS treats the very shortest baselines. However, the fact that the effect is found in power spectra derived from time-ordered visibilities as well as image cubes, suggests that the effect is likely not due treatment of gridding or image reconstruction but rather in calibration or foreground subtraction steps.


The major difference between the power spectrum methods is in the calculation and minimization of $uvf$ covariance.   CHIPS aims to diagonalize by covariance between $k$ voxels but to do so it must take on more of the instrument modeling. Meanwhile, \eppsilon{} leaves the modeling to the foreground subtraction step and assumes that, to first order, covariance has been minimized by an additional down-weighting by the primary beam of the instrument.  

The practical outcome of this difference is that CHIPS takes full advantage of the covariance weighting in the average to the 1D averaged power spectrum; the 2D CHIPS power spectrum does not benefit from . The result is that it is not as optimized for making 2D power spectra as \eppsilon{}.  The 1D power spectra shown in Figure \ref{fig:1D_pspecs}, indicate a good number of points which are consistent with zero.

The final analysis step is to average into 1D power spectra along shells of constant $k$. These are shown in Figure \ref{fig:1D_pspecs} for three of the four analysis tracks\footnote{The shorter RTS$\to$\eppsilon{} integration is excluded because it doesn't have the same sensitivity and complicates the comparison.} shown in Figure \ref{fig:pspec_compare} and with the addition of \dilloncite{} points. Here an interesting comparison can be made between two alternative covariance weightings; CHIPS down-weights by an a-priori statistical model of confused foregrounds while \empirical{} makes an empirical estimate of the covariance in the data. Both down-weighting schemes  decrease the amount of power leaking into the lowest $k$ modes, though at low $k$ CHIPS finds higher power than the Dillon scheme.  That the two methods do arrive at similar answers suggest that much of the residual covariance can be modeled as foreground rather than instrumental systematic. All points and limits are a factor of a few above the estimated sensitivity level corresponding to a three hour integration, calculated using the 21CMSENSE sensitivity code\footnote{\url{github.com/jpober/21cmsense/}} by \cite{Pober:2014p10390}.

%K space cuts make a huge difference and are very different between the different 1d pspecs
% FHD->eppsilon  
%  kperp range in lambda = [10,50]
%  kpar range  = [0.2,10]
%  + strictly above the horizon.
% RTS-> CHIPS

% Josh
%     kpar >4.62*kperp+0.02



%Thus one of the largest differences is in the amount of correlation along the vertical, or line-of-sight, direction.  Both CHIPs and \eppsilon{}, when applied to their  primary foreground subtraction strategy (FHD for \eppsilon{} and RTS for CHIPS), have minimal line-of-sight covariance at low $k_\perp$ where frequency to frequency variation in $uv$ sampling is small. At high $k_\perp$ \eppsilon{}'s simplistic Fourier Transform reveals the large residual correlation between different $uv\eta$ cells caused by the fact that baseline length changes quickly with frequency.  \eppsilon{} has so far not accounted for covariance choosing speed over accuracy on long baselines.


%The final analysis step is to average the 2D power spectra into 1D radial averages, shown in Figure \ref{fig:1D_pspecs} for \empirical{} and CHIPS applied to FHD. In three hours of data the two independent methods demonstrate similar, largely noise limited, measurements of the power spectrum.  The red points are weighted by an empirical estimate of foreground-like covariance and are further described in \dilloncite{}.  The black points are computed using the CHIPS estimator and then further weighted by a model of the confused foregrounds and are further described in \chipscite{}. Both down-weighting schemes  decrease the amount of power leaking into the lowest $k$ modes, though at low $k$ CHIPS finds somewhat higher power than the Dillon scheme. This is not inconsistent with the differences in method. CHIPS limits its down-weighting to a model of residual foreground covariance caused by a stochastic background of confused point sources while \empirical{} uses a model of covariance derived from the data itself (though limited in free parameters so as to minimized signal loss). That the two methods do arrive at similar answers suggest that much of the residual covariance can be modeled as foreground rather than instrumental systematic.     Any remaining excesses in this plot are thought to be consistent with a fairly aggressive inclusion of the parts of $k$-space near to the wedge --in this case points up to 0.02Mpc$^{-1}$ away from the horizon (the solid black line in Figure \ref{fig:pspec_compare}) were included-- and known systematics like cable reflections. At high $k$ values both methods are in good agreement with each other and with the theoretical noise level; given the data included we expect a $\sqrt{2}$ difference in the noise level.  

%Using the speedup provided by \eppsilon, many iterations of ``preview'' power spectra were used to view the effect of calibration and flagging choices on the power spectrum. For example the wide-field effects, described in detail by \cite{2015arXiv150207596T}, are clearly visible in power spectra computed by \eppsilon{} and are seen to be stronger for certain configurations of pointing and sky. Removing these portions of the data eliminated a substantial amount of bleed from the wedge into the window.  Using this and other jackknife selections we arrived at a refined data FHD image cube which was then carried into the \empirical cov analysis resulting in the power spectra shown in Figure \ref{fig:1D_pspecs}.   Though well above the predicted signal level the 2$\sigma$ error bars are mostly consistent with noise.   Residual excesses --particularly near low $k$s--  are consistent with a fairly aggressive inclusion of points near to the wedge, in this case points up to 0.02$Mpc^{-1}$ away from the horizon (the solid black line in Figure \ref{fig:pspec_compare})were included.





\begin{figure*}[h!]
\begin{center}
\includegraphics[width=0.8\textwidth]{figures/MWA_PS_compare/MWA_PS_compare.png}
\caption{Power spectra computed using two foreground subtraction methods and two power spectrum estimation methods on the data shown in Figure \ref{fig:image_compare}, the 3D power spectrum has been computed in full 3D and then averaged cylindrically.  In the top row data have been calibrated and foreground subtracted using the Fast Holographic Deconvolution method, in the bottom row by the MWA Real Time System.  In the left column, power spectra have been estimated with \eppsilon, which emphasizes speed and full error propagation, in the right column, CHIPS corrects more correlation between $k$ modes.  All spectra display the now well-understood ``wedge''-shaped foreground residual and horizontal stripes caused by evenly spaced gaps in the instrument pass-band.  \empirical{} 2D power spectra were not included in the \dilloncite{} analysis. \label{fig:pspec_compare}}
\end{center}
\end{figure*}


\begin{figure}[htbp]
\begin{center}
\includegraphics[width=0.5\textwidth]{figures/MWAPipeline_compare_1d_kperp}
\caption{Horizontal cut sampling the $k_\parallel = 0$ mode of the 2D power spectra shown in Figure \ref{fig:pspec_compare} indicating good agreement over most k modes.}
\label{fig:1d_kperp}
\end{center}
\end{figure}


\begin{figure*}[h!]

\includegraphics[width=\textwidth]{figures/MWA_PS_Compare/MWAPipeline_compare_1d_radial_logbryna.png}
\caption{Power spectra averaged along shells of constant $|k|$. In three hours of data, four different methods demonstrate similar limits on the power spectrum. Note that of the four pathways shown in Figure \ref{fig:pspec_compare}, only three are included here. We have also included an additional 1D estimate made with the Dillon et. al inverse covariance method. In all methods, save \eppsilon{}, power and errors have been estimated with some variant of Many of the features visible in the 2D plots are also visible here. Points at or below $k<0.3$ are dominated by the foreground wedge. These are accessible only if the estimated power is down-weighted by the foreground residual as it is in all methods shown here, save \eppsilon{} where the points have been excluded. The black curve indicates the 1$\sigma$ bounds of points dominated by noise.  Power levels for typical theoretical models are typically in the 5 to 10 mK$^2$ range across these $k$ modes.
\label{fig:1D_pspecs}}

\end{figure*}
%\begin{figure*}[h!]
%\begin{center}
%\includegraphics[width=\textwidth]{figures/1dDeltaSqComparisonFHD.pdf}
%\caption{Here we have power spectra averaged along shells of constant $|k|$ where foregrounds have been further down-weighted by inverse covariance after calibration and foreground subtraction by FHD. In three hours of data, two independent methods demonstrate similar, largely noise limited, measurements of the power spectrum.  A theoretical model (blue, \cite{Barkana:2009p1454}) sets the scale.  The red points are weighted by an empirical estimate of foreground-like covariance and are described in \dilloncite.  The black points are computed using the CHIPS estimator and then further weighted by a model of the confused foregrounds and are further described in \chipscite. The action of both foreground down-weighting schemes is to decrease the amount of power leaking from the very lowest $k$ modes. At low $k$ CHIPS finds somewhat higher power, as discussed in the text this is not inconsistent with the differences in the weight models   The very high CHIPS point  is dominated by a very small amount of data, but is included for completeness.  At high $k$ values both methods are in good agreement with each other and with the theoretical noise level (this line has been omitted for clarity); given the data included we expect a $\sqrt{2}$ difference in the noise level.  Any remaining excesses in this plot are thought to be consistent with a fairly aggressive inclusion of points near to the wedge --in this case points up to 0.02Mpc$^{-1}$ away from the horizon (the solid black line in Figure \ref{fig:pspec_compare}) were included-- and known systematics like cable reflections.\label{fig:1D_pspecs}}
%\end{center}
%\end{figure*}


\section{Lessons from Comparing Independent Pipelines}
\label{sec:lessons}
      A data analysis pipeline is necessarily built on a complex software framework which is only imperfectly described in prose and is susceptible to human error.  Comparison between independently developed analysis paths, each with their own strengths and limitations is essential to placing believable constraints on the Epoch of Reionization. The ongoing comparison between independent MWA pipelines has revealed a number of issues both systematic (related to our understanding of the instrument or foregrounds) and algorithmic (optimizing our use of this knowledge) which we will briefly mention here.
      
\begin{itemize}

\item \emph{ Systematic example: cable reflections}

As discussed above, one significant difference between the two pipelines is the number of free parameters fit in the calibration step, particularly in the spectral dimension.  Both calibration pipelines begin by calibrating each channel and then averaging over a number of axes.  The RTS fits a low order polynomial, piecewise, to each of the 24 1.28MHz sub-band solutions, while FHD fits a similar order polynomial to the entire  band's calibration solution.  Inspection of power spectra calibrated using the FHD scheme revealed previously unknown spectral features corresponding to reflections on the analog cables at the -20dB level (~1.5\%). FHD calibration now includes a fit for these reflections and the feature is no longer visible. These features are fully covered by the RTS fit (which uses of order 10 times as many free parameters as FHD). 

\item \emph{Calibration example: number of sources}

In first comparisons between RTS and FHD images one immediately apparent difference was the somewhat lower dynamic range of the RTS image.  This was traced to the largest (at the time) difference between the two approaches; RTS used the more traditional radio astronomy practice of calibrating to a pointing on a bright source at the beginning of each night and then transferring the calibration to the rest of the observations, whereas FHD was calibrating against the foreground model. This dramatically highlighted the breakdown of approaches designed for narrow fields of view. Not only did the ``calibration observation'' also have thousands of bright sources vying for attention with the target calibrator, but, owing to the phased array steering, the primary beam for the calibrator pointing is very different from the beams used for the primary reionization observations. So, though the instrument itself is highly stable in time over many hours, calibrations must be carefully matched up with the observing parameters or experience a dramatic loss of imaging dynamic range, both spatially and spectrally. The addition of ``in field'' calibration, where the foreground subtraction model is also the calibration model significantly improved the RTS images and brought them into good agreement.


\item \emph{Algorithmic example: full forward modeling for absolute calibration and signal loss}

During the comparison process, one way in which all pipeline results differed from each other is in the overall amplitude of the power spectrum scale. To agree the overall flux calibration, weightings, and Fourier conventions must all be well understood.  Perhaps the most important factor is assessment of signal loss.  Unintential or unavoidable down-weighting or subtraction of reionization signal could occur at multiple stages such as bandpass calibration, $uvf$ gridding, or inverse covariance weighting. This loss is best calibrated via forward modeling of a simulated reionization signal and in the process provides verification of the overall power spectrum scale.  Such simulations have been used to verify the various steps in the FHD-\eppsilon{} pipeline and by stepping through the pipeline at each major operation have been shown to be self-consistent (see \eppsiloncite{}) and suitable for calibration of the other pipelines.

\item \emph{Algorithmic example: w-planes in power spectrum calculation}

\textbf{TODO: Cath check}

Many of the differences found between power spectra during the comparison were traced to the post-foreground-subtraction steps, particularly the implementation of new imaging and power spectrum estimation codes.  One example was an anomalous loss of power in CHIPS power spectra which particularly effected longer baselines.  CHIPS grids in a coordinate space defined by the baseline vector $\vec{b}$ and spectral mode $\eta$ and then uses an instrument model to diagonalize and sum in this sparse power spectrum space.  Unlike FHD which uses snapshots to avoid directly handling the third or `w' term of the baseline vector, CHIPS accumulates the entire observation into a full uvw$\eta$ cube.  The number and size of the voxels in this space, particularly in the w direction is a somewhat free parameter and relates to the precision of the instrument model, the amount of time included and other factors.  Subsequent more detailed foreground simulations suggested a factor of 4 w resolution increase which eliminated the signal loss and dramatically improved agreement.


\item \emph{Interchange standards}

Finally, in the interest of transparency, we offer a somewhat prosaic but perhaps vital lesson regarding polarization nomenclature for fixed dipole arrays for which there are (at least) two popular and mutually exclusive traditions. Tradition A: In keeping with the traditional abscissa of latitude longitude plots, the east-west oriented dipole is labeled X.  Tradition B: Astronomically, the X polarization is measured as the amplitude of a dipole aligned with lines of constant Right Ascension; which for a source at zenith maps to north-south. We humbly suggest that those pursuing a cross comparison effort select one standard at the outset. 

\end{itemize}






  We must stress that without the ability to compare between independent pipelines, most of these effects would have gone un-detected or mis-diagnosed as algorithmic deficiencies and have persisted into the final result or motivated additional fitting parameters resulting in higher signal loss as well as a vague disquiet. In addition to pipeline redundancy, forward modeling can provide some important checks, for example the absolute calibration of FHD and \eppsilon{} described in \eppsiloncite{}, however the result is only as good as the model itself.
  
\section{Conclusions}
\label{sec:conclusion}
In this overview paper we have provided a top level view of foreground subtraction and power spectrum estimation methods described more completely in companion papers \eppsiloncite{}, \chipscite{}, and \dilloncite{}.  In this comparison we see that both foreground subtraction methods are able to reliably remove similar amounts of power.  Differences between the images are smaller than the remaining residual foregrounds by a factor of 3.2, suggesting an overall $\sim$30\% error on the aggregate calibration, foreground subtraction and imaging between the two pipelines.  The power spectra of these foreground subtracted outputs agree on the scale and distribution of power, though with some differences in the leakage of power into the window. These differences become less interesting when the error bars are taken into consideration.    


The one dimensional power spectra are the final science product. Though none of the power spectra are identical, the degree of agreement and the success at making very similar measurements gives us confidence in pipeline accuracy going forward to deeper integrations. Most importantly in validating the pipeline at this level it has become easier to draw conclusions about the relative quality of the data independent of concerns about the processing of the data; bad data is truly bad and not evidence of an underlying software or algorithmic problem.  

Using this validated pipeline to make quick estimates of the power spectrum in different selections of data we were able to select a high quality set, with a well understood calibration, for application of the empirical  covariance technique and generate a noise limited measurement.  The 1D power spectrum presented here and in \dilloncite{} is roughly 500 times deeper then the previous MWA power spectrum \citep{Dillon:2014p9788} which was done using roughly the same amount of integration time but only 32 of the present 128 tiles.  Future work will focus on refining calibration and weighting schemes to more accurately reconstruct large scale power and building on deeper integrations using data collected in recent observing campaigns.




\acknowledgments

This work was supported	 by the U. S. National Science Foundation (NSF) through award AST--1109257. DCJ is supported by an NSF Astronomy and Astrophysics Postdoctoral Fellowship under award AST--1401708. JCP is supported by an NSF Astronomy and Astrophysics Fellowship under award AST-1302774. This scientific work makes use of the Murchison Radio-astronomy Observatory, operated by CSIRO. We acknowledge the Wajarri Yamatji people as the traditional owners of the Observatory site. Support for the MWA comes from the U.S. National Science Foundation (grants AST-0457585, PHY-0835713, CAREER-0847753, and AST-0908884), the Australian Research Council (LIEF grants LE0775621 and LE0882938), the U.S. Air Force Office of Scientific Research (grant FA9550-0510247), and the Centre for All-sky Astrophysics (an Australian Research Council Centre of Excellence funded by grant CE110001020). Support is also provided by the Smithsonian Astrophysical Observatory, the MIT School of Science, the Raman Research Institute, the Australian National University, and the Victoria University of Wellington (via grant MED-E1799 from the New Zealand Ministry of Economic Development and an IBM Shared University Research Grant). The Australian Federal government provides additional support via the Commonwealth Scientific and Industrial Research Organisation (CSIRO), National Collaborative Research Infrastructure Strategy, Education Investment Fund, and the Australia India Strategic Research Fund, and Astronomy Australia Limited, under contract to Curtin University. We acknowledge the iVEC Petabyte Data Store, the Initiative in Innovative Computing and the CUDA Center for Excellence sponsored by NVIDIA at Harvard University, and the International Centre for Radio Astronomy Research (ICRAR), a Joint Venture of Curtin University and The University of Western Australia, funded by the Western Australian State government.
\bibliography{bibliography/library}

\end{document}

%TODO:
% 4 panel k range, fonts and scales (CATH is DONE, waiting on Bryna's line update).
% update abstract (DONE)
% update FHD->CHIPS files  (in progress)
% CHIPS 1d outputs, horizon avoidance.
% w-plane lesson (DONE, needs fact checking by Cath)
% RTS megapatch lesson (DONE needs fact checking by Bart)
% polarization standard (DONE)
% awesome title(DONE)
% add EoR FoV figure
% add X error bars to Cath's points (DONE)