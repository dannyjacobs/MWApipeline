\subsection{Imager \#2: FHD}
Fast Holographic Deconvolution (FHD, \citet{an_Bunton_Cappallo_et_al__2012}) is a calibration and imaging algorithm designed for very wide field of view interferometers with direction- and antenna-dependent beam patterns. FHD has particularly been designed with a focus on producing an accurate measurement of the power spectrum complete with proper error propagation. In particular, we use the holographic beam pattern for gridding visibilities to the u-v plane, and its Hermitian conjugate for de-gridding simulations to form model visibilities. The holographic beam model is composed of the measured antenna response to the electric field for each antenna element and at every fine frequency channel, convolved with the response of the second antenna that forms the visibility. Three data outputs are necessary from gridding in order to calculate the image based power spectrum with accurate error bars: the measured visibilities, gridded with the holographic beam model\footnote{Note that the resulting image will be tapered by the average primary beam squared}; the weights, obtained by gridding the holographic beam model; and the variance, obtained by gridding the squared holographic beam model.

The FHD calibration and imaging pipeline both measures and removes foregrounds. In the first mode, we deconvolve a deep observation with XXX hours on each field (a small fraction of the total data) to generate a high quality map of the foregrounds. This foreground model includes both compact and extended sources and diffuse structure such as the galaxy, and it is used as an input to the second FHD imaging mode. In the second mode we process all 1000 hours of EoR observations, but do not perform any deconvolution. Instead, we generate model visibilities using the full polarized direction-dependent antenna gains, and calculate the on-field direction-independent calibration solutions for each 112s EoR snapshot. The residual visibilities formed by subtracting the calibration model from the data are first saved and sent to the visibility-based power spectrum pipeline (section XXX), and then gridded (again using the polarized primary beam) along with the weights and variance for the image-based power spectrum pipeline (section XXX). The snapshot image, weights, and variance cubes are fourier transformed into the image domain. Deep integrations are produced by gridding all of these products into single HEALPix maps.
